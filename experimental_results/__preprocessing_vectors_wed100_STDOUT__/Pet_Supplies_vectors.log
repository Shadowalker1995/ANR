
Dataset: Pet_Supplies

[args from argparse.ArgumentParser().parse_args()]
command: pretrained_vectors_simple.py -emb_dim 100 -d Pet_Supplies
dataset: Pet_Supplies
emb_dim: 100
emb_rand_init: 0.01
random_seed: 1337

[INPUT] Source Folder:                 ../datasets/
[INPUT] Category Folder:               ../datasets/Pet_Supplies/
[INPUT] env:                           ../datasets/Pet_Supplies/Pet_Supplies_env.pkl
[INPUT] Pretrained Word Embeddings:    ../datasets/glove.twitter.word2vec.27B.100d.txt

[OUTPUT] wid_wordEmbed:                ../datasets/Pet_Supplies/Pet_Supplies_wed100_wid_wordEmbed.npy

Loading word-to-wid mappings (i.e. word_wid) from "../datasets/Pet_Supplies/Pet_Supplies_env.pkl"

|V|: 50002

Finished processing pretrained embeddings..
# of words with pretrained embeddings: 37318

Embedding Matrix=(50002, 100), |V|=50002
# of Words w/ No Pretrained Embeddings=12684 (25.367%)

Embeddings successfully saved to '../datasets/Pet_Supplies/Pet_Supplies_wed100_wid_wordEmbed.npy'


Pretrained word embeddings for "Pet_Supplies" obtained after 75.58 seconds (1.26 minutes)

