========================================================================================================================
  ARL_lr: 0.01
  ARL_path: 
  batch_size: 128
  channels_global: 10
  channels_local: 10
  command: -d Small_Clothing -m VANRA -e 10 -dr 0.9 -p 1 -v 43947 -K 5 -h1 10 -h2 50 -c_local 10 -c_global 10 -hiden_size 200 -output_size 50 -rs 1234 -gpu 0 -vb 1 -sm Small_Clothing_VANRA
  ctx_win_size: 3
  dataset: Small_Clothing
  disable_initial_eval: 0
  dropout_rate: 0.9
  epochs: 10
  gpu: 0
  h1: 10
  h2: 50
  hidden_size: 200
  input_dir: ./datasets/Small_Clothing/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  max_vis_len: 500
  model: VANRA
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Small_Clothing - VANRA/
  output_size: 50
  pretrained_src: 1
  random_seed: 1234
  save_model: Small_Clothing_VANRA
  use_cuda: True
  verbose: 1
  vocab_size: 43947
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 77,930, # of Items: 59,172

Creating model (Selected Model: VANRA)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 2.49s (0.04 minute)

Loading uid_userDoc from "./datasets/Small_Clothing/Small_Clothing_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (77930, 500)]

Loading iid_itemDoc from "./datasets/Small_Clothing/Small_Clothing_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (59172, 500)]

Loading pretrained word embeddings from "./datasets/Small_Clothing/Small_Clothing_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (43949, 300)]

Loading uid_userVis from "./datasets/Small_Clothing/Small_Clothing_uid_userVis.npy"..
uid_userVis loaded! [uid_userVis: (77930, 500)]

Loading iid_itemVis from "./datasets/Small_Clothing/Small_Clothing_iid_itemVis.npy"..
iid_itemVis loaded! [iid_itemVis: (59172, 500)]

Initialization Complete.. Elapsed Time: 3.05s (0.05 minute)

Train/Dev/Test splits loaded! |TRAIN|: 80,000, |DEV|: 150, |TEST|: 166
Train/Dev/Test splits loaded! Elapsed Time: 3.07s (0.05 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 18.56397, MAE: 4.18031

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 19.30633, MAE: 4.27780

Initial Evaluation Complete.. Elapsed Time: 3.24s (0.05 minute)

Parameters with L2 Regularization (Regularization Strength: 1e-06):
VANRA_RatingPred.uid_userOffset.weight, VANRA_RatingPred.iid_itemOffset.weight

Optimizer: Adam, Loss Function: MSELoss

Model Size: 158,549,693
# of Trainable Parameters: 8,262,993
VANRA (
  (uid_userDoc): Embedding(77930, 500), weights = ((77930, 500),), parameters = 38,965,000
  (iid_itemDoc): Embedding(59172, 500), weights = ((59172, 500),), parameters = 29,586,000
  (wid_wEmbed): Embedding(43949, 300), weights = ((43949, 300),), parameters = 13,184,700
  (uid_userVis): Embedding(77930, 500), weights = ((77930, 500),), parameters = 38,965,000
  (iid_itemVis): Embedding(59172, 500), weights = ((59172, 500),), parameters = 29,586,000
  (shared_ANR_ARL): ANR_ARL(
    (aspEmbed): Embedding(5, 30)
    (aspProj): Parameter(5, 300, 10)
  ), weights = ((5, 300, 10), (5, 30)), parameters = 15,150 (Trainable)
  (ANR_AIE): ANR_AIE(  (W_a): Parameter(10, 10)
    (W_u): Parameter(50, 10)
    (w_hu): Parameter(50, 1)
    (W_i): Parameter(50, 10)
    (w_hi): Parameter(50, 1)
  ), weights = ((10, 10), (50, 10), (50, 1), (50, 10), (50, 1)), parameters = 1,200 (Trainable)
  (VANRA_VRL): VANRA_VRL(
    (localAttentionLayer_user): LocalAttention(
      (attention_layer): Sequential(
        (0): Conv2d(1, 1, kernel_size=(3, 1), stride=(1, 1))
        (1): Softmax(dim=2)
      )
      (cnn): Sequential(
        (0): Conv2d(1, 10, kernel_size=(1, 1), stride=(1, 1))
        (1): Tanh()
      )
      (fcLayer): Sequential(
        (0): Linear(in_features=5000, out_features=200, bias=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): ReLU()
        (3): Linear(in_features=200, out_features=50, bias=True)
      )
    )
    (globalAttentionLayer_user): GlobalAttention(
      (attention_layer): Sequential(
        (0): Conv2d(1, 1, kernel_size=(500, 1), stride=(1, 1))
        (1): Sigmoid()
      )
      (cnn_1): Sequential(
        (0): Conv2d(1, 10, kernel_size=(2, 1), stride=(1, 1))
        (1): Tanh()
      )
      (fcLayer1): Sequential(
        (0): Linear(in_features=4990, out_features=200, bias=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): ReLU()
        (3): Linear(in_features=200, out_features=50, bias=True)
      )
      (cnn_2): Sequential(
        (0): Conv2d(1, 10, kernel_size=(3, 1), stride=(1, 1))
        (1): Tanh()
      )
      (fcLayer2): Sequential(
        (0): Linear(in_features=4980, out_features=200, bias=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): ReLU()
        (3): Linear(in_features=200, out_features=50, bias=True)
      )
      (cnn_3): Sequential(
        (0): Conv2d(1, 10, kernel_size=(4, 1), stride=(1, 1))
        (1): Tanh()
      )
      (fcLayer3): Sequential(
        (0): Linear(in_features=4970, out_features=200, bias=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): ReLU()
        (3): Linear(in_features=200, out_features=50, bias=True)
      )
    )
    (localAttentionLayer_item): LocalAttention(
      (attention_layer): Sequential(
        (0): Conv2d(1, 1, kernel_size=(3, 1), stride=(1, 1))
        (1): Softmax(dim=2)
      )
      (cnn): Sequential(
        (0): Conv2d(1, 10, kernel_size=(1, 1), stride=(1, 1))
        (1): Tanh()
      )
      (fcLayer): Sequential(
        (0): Linear(in_features=5000, out_features=200, bias=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): ReLU()
        (3): Linear(in_features=200, out_features=50, bias=True)
      )
    )
    (globalAttentionLayer_item): GlobalAttention(
      (attention_layer): Sequential(
        (0): Conv2d(1, 1, kernel_size=(500, 1), stride=(1, 1))
        (1): Sigmoid()
      )
      (cnn_1): Sequential(
        (0): Conv2d(1, 10, kernel_size=(2, 1), stride=(1, 1))
        (1): Tanh()
      )
      (fcLayer1): Sequential(
        (0): Linear(in_features=4990, out_features=200, bias=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): ReLU()
        (3): Linear(in_features=200, out_features=50, bias=True)
      )
      (cnn_2): Sequential(
        (0): Conv2d(1, 10, kernel_size=(3, 1), stride=(1, 1))
        (1): Tanh()
      )
      (fcLayer2): Sequential(
        (0): Linear(in_features=4980, out_features=200, bias=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): ReLU()
        (3): Linear(in_features=200, out_features=50, bias=True)
      )
      (cnn_3): Sequential(
        (0): Conv2d(1, 10, kernel_size=(4, 1), stride=(1, 1))
        (1): Tanh()
      )
      (fcLayer3): Sequential(
        (0): Linear(in_features=4970, out_features=200, bias=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): ReLU()
        (3): Linear(in_features=200, out_features=50, bias=True)
      )
    )
    (fcLayer): Sequential(
      (0): Linear(in_features=200, out_features=200, bias=True)
      (1): ReLU()
      (2): Linear(in_features=200, out_features=50, bias=True)
    )
  ), weights = ((1, 1, 3, 1), (1,), (10, 1, 1, 1), (10,), (200, 5000), (200,), (50, 200), (50,), (1, 1, 500, 1), (1,), (10, 1, 2, 1), (10,), (200, 4990), (200,), (50, 200), (50,), (10, 1, 3, 1), (10,), (200, 4980), (200,), (50, 200), (50,), (10, 1, 4, 1), (10,), (200, 4970), (200,), (50, 200), (50,), (1, 1, 3, 1), (1,), (10, 1, 1, 1), (10,), (200, 5000), (200,), (50, 200), (50,), (1, 1, 500, 1), (1,), (10, 1, 2, 1), (10,), (200, 4990), (200,), (50, 200), (50,), (10, 1, 3, 1), (10,), (200, 4980), (200,), (50, 200), (50,), (10, 1, 4, 1), (10,), (200, 4970), (200,), (50, 200), (50,), (200, 200), (200,), (50, 200), (50,)), parameters = 8,109,540 (Trainable)
  (VANRA_RatingPred): VANRA_RatingPred(
    (userAspRepDropout): Dropout(p=0.9, inplace=False)
    (itemAspRepDropout): Dropout(p=0.9, inplace=False)
    (uid_userOffset): Embedding(77930, 1)
    (iid_itemOffset): Embedding(59172, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (77930, 1), (59172, 1)), parameters = 137,103 (Trainable)
)
========================================================================================================================

[Epoch 1/10] Training Loss: 3.01176	Elapsed Time: 31.26s (0:00:31)
[Epoch 1] [Dev]  MSE: 7.14522, MAE: 2.50950
[Epoch 1] [Test] MSE: 7.55575, MAE: 2.60473

*** MODEL has obtained the best DEV MSE of 7.14522 so far!
*** The Best MODEL saved to "./__saved_models__/Small_Clothing - VANRA/Small_Clothing_VANRA_1234.pth"

[Epoch 2/10] Training Loss: 1.56889	Elapsed Time: 62.76s (0:01:02)
[Epoch 2] [Dev]  MSE: 5.60526, MAE: 2.20631
[Epoch 2] [Test] MSE: 5.98218, MAE: 2.30270

*** MODEL has obtained the best DEV MSE of 5.60526 so far!
*** The Best MODEL saved to "./__saved_models__/Small_Clothing - VANRA/Small_Clothing_VANRA_1234.pth"

[Epoch 3/10] Training Loss: 1.37715	Elapsed Time: 93.99s (0:01:33)
[Epoch 3] [Dev]  MSE: 3.68230, MAE: 1.77710
[Epoch 3] [Test] MSE: 3.95337, MAE: 1.84596

*** MODEL has obtained the best DEV MSE of 3.68230 so far!
*** The Best MODEL saved to "./__saved_models__/Small_Clothing - VANRA/Small_Clothing_VANRA_1234.pth"

[Epoch 4/10] Training Loss: 1.20764	Elapsed Time: 125.22s (0:02:05)
[Epoch 4] [Dev]  MSE: 2.79956, MAE: 1.53099
[Epoch 4] [Test] MSE: 3.02996, MAE: 1.59608

*** MODEL has obtained the best DEV MSE of 2.79956 so far!
*** The Best MODEL saved to "./__saved_models__/Small_Clothing - VANRA/Small_Clothing_VANRA_1234.pth"

[Epoch 5/10] Training Loss: 1.09650	Elapsed Time: 156.44s (0:02:36)
[Epoch 5] [Dev]  MSE: 2.94726, MAE: 1.57841
[Epoch 5] [Test] MSE: 3.20296, MAE: 1.63805

[Epoch 6/10] Training Loss: 0.98565	Elapsed Time: 187.53s (0:03:07)
[Epoch 6] [Dev]  MSE: 2.77729, MAE: 1.52761
[Epoch 6] [Test] MSE: 3.08312, MAE: 1.60625

*** MODEL has obtained the best DEV MSE of 2.77729 so far!
*** The Best MODEL saved to "./__saved_models__/Small_Clothing - VANRA/Small_Clothing_VANRA_1234.pth"

[Epoch 7/10] Training Loss: 0.89269	Elapsed Time: 219.14s (0:03:39)
[Epoch 7] [Dev]  MSE: 2.69099, MAE: 1.50223
[Epoch 7] [Test] MSE: 2.99460, MAE: 1.58293

*** MODEL has obtained the best DEV MSE of 2.69099 so far!
*** The Best MODEL saved to "./__saved_models__/Small_Clothing - VANRA/Small_Clothing_VANRA_1234.pth"

[Epoch 8/10] Training Loss: 0.79750	Elapsed Time: 251.51s (0:04:11)
[Epoch 8] [Dev]  MSE: 2.28287, MAE: 1.37350
[Epoch 8] [Test] MSE: 2.55262, MAE: 1.45147

*** MODEL has obtained the best DEV MSE of 2.28287 so far!
*** The Best MODEL saved to "./__saved_models__/Small_Clothing - VANRA/Small_Clothing_VANRA_1234.pth"

[Epoch 9/10] Training Loss: 0.71947	Elapsed Time: 283.69s (0:04:43)
[Epoch 9] [Dev]  MSE: 2.18302, MAE: 1.33585
[Epoch 9] [Test] MSE: 2.44086, MAE: 1.41387

*** MODEL has obtained the best DEV MSE of 2.18302 so far!
*** The Best MODEL saved to "./__saved_models__/Small_Clothing - VANRA/Small_Clothing_VANRA_1234.pth"

[Epoch 10/10] Training Loss: 0.63605	Elapsed Time: 315.73s (0:05:15)
[Epoch 10] [Dev]  MSE: 2.29068, MAE: 1.36866
[Epoch 10] [Test] MSE: 2.56240, MAE: 1.44633
*** The Last MODEL saved to "./__saved_models__/Small_Clothing - VANRA/Small_Clothing_VANRA_1234_10.pth"

[Training Loss]
[3.01176, 1.56889, 1.37715, 1.20764, 1.0965, 0.98565, 0.89269, 0.7975, 0.71947, 0.63605]

[Dev MSE]
[7.14522, 5.60526, 3.6823, 2.79956, 2.94726, 2.77729, 2.69099, 2.28287, 2.18302, 2.29068]
[Test MSE]
[7.55575, 5.98218, 3.95337, 3.02996, 3.20296, 3.08312, 2.9946, 2.55262, 2.44086, 2.5624]
[Test MAE]
[2.60473, 2.3027, 1.84596, 1.59608, 1.63805, 1.60625, 1.58293, 1.45147, 1.41387, 1.44633]


Best Dev MSE: 2.18302 (Obtained during Evaluation #9)
Test MSE: 2.44086, Test MAE: 1.41387

End of Program! Elapsed Time: 319.16s (0:05:19)
