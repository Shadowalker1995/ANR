========================================================================================================================
  ARL_lr: 0.01
  ARL_path: 
  batch_size: 128
  channels_global: 100
  channels_local: 200
  command: -d Movies_and_TV -m DAttn -e 10 -p 1 -v 50000 -K 5 -h1 10 -h2 50 -WED 100 -c_local 200 -c_global 100 -hiden_size 500 -output_size 50 -rs 1234 -gpu 0 -vb 1 -sm Movies_and_TV_DAttn
  ctx_win_size: 3
  dataset: Movies_and_TV
  disable_initial_eval: 0
  dropout_rate: 0.5
  epochs: 10
  filters_num: 100
  gpu: 0
  h1: 10
  h2: 50
  hidden_size: 500
  input_dir: ./datasets/Movies_and_TV/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  max_vis_len: 500
  model: DAttn
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Movies_and_TV - DAttn/
  output_size: 50
  pretrained_src: 1
  random_seed: 1234
  save_model: Movies_and_TV_DAttn
  use_cuda: True
  verbose: 1
  vocab_size: 50000
  word_embed_dim: 100
========================================================================================================================

[INFO] # of Users: 541,405, # of Items: 106,040

Creating model (Selected Model: DAttn)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 3.82s (0.06 minute)

Loading uid_userDoc from "./datasets/Movies_and_TV/Movies_and_TV_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (541405, 500)]

Loading iid_itemDoc from "./datasets/Movies_and_TV/Movies_and_TV_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (106040, 500)]

Loading pretrained word embeddings from "./datasets/Movies_and_TV/Movies_and_TV_wed100_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (50002, 100)]

Initialization Complete.. Elapsed Time: 24.68s (0.41 minute)

Train/Dev/Test splits loaded! |TRAIN|: 800,000, |DEV|: 40,918, |TEST|: 41,059
Train/Dev/Test splits loaded! Elapsed Time: 24.95s (0.42 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 18.88589, MAE: 4.17711

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 18.88224, MAE: 4.17562

Initial Evaluation Complete.. Elapsed Time: 43.39s (0.72 minute)

Optimizer: Adam, Loss Function: MSELoss

Model Size: 330,242,850
# of Trainable Parameters: 1,520,150
DAttn (
  (uid_userDoc): Embedding(541405, 500), weights = ((541405, 500),), parameters = 270,702,500
  (iid_itemDoc): Embedding(106040, 500), weights = ((106040, 500),), parameters = 53,020,000
  (wid_wEmbed): Embedding(50002, 100), weights = ((50002, 100),), parameters = 5,000,200
  (user_net): Net(
    (localAttentionLayer): LocalAttention(
      (attention_layer): Sequential(
        (0): Conv2d(1, 1, kernel_size=(3, 100), stride=(1, 1), padding=(1, 0))
        (1): Sigmoid()
      )
      (cnn): Sequential(
        (0): Conv2d(1, 200, kernel_size=(1, 100), stride=(1, 1))
        (1): Tanh()
      )
    )
    (globalAttentionLayer): GlobalAttention(
      (attention_layer): Sequential(
        (0): Conv2d(1, 1, kernel_size=(500, 100), stride=(1, 1))
        (1): Sigmoid()
      )
      (convs): ModuleList(
        (0): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1))
        (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))
        (2): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))
      )
    )
    (fcLayer): Sequential(
      (0): Linear(in_features=500, out_features=500, bias=True)
      (1): Dropout(p=0.5, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=500, out_features=50, bias=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  ), weights = ((1, 1, 3, 100), (1,), (200, 1, 1, 100), (200,), (1, 1, 500, 100), (1,), (100, 1, 2, 100), (100,), (100, 1, 3, 100), (100,), (100, 1, 4, 100), (100,), (500, 500), (500,), (50, 500), (50,)), parameters = 436,352 (Trainable)
  (item_net): Net(
    (localAttentionLayer): LocalAttention(
      (attention_layer): Sequential(
        (0): Conv2d(1, 1, kernel_size=(3, 100), stride=(1, 1), padding=(1, 0))
        (1): Sigmoid()
      )
      (cnn): Sequential(
        (0): Conv2d(1, 200, kernel_size=(1, 100), stride=(1, 1))
        (1): Tanh()
      )
    )
    (globalAttentionLayer): GlobalAttention(
      (attention_layer): Sequential(
        (0): Conv2d(1, 1, kernel_size=(500, 100), stride=(1, 1))
        (1): Sigmoid()
      )
      (convs): ModuleList(
        (0): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1))
        (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))
        (2): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))
      )
    )
    (fcLayer): Sequential(
      (0): Linear(in_features=500, out_features=500, bias=True)
      (1): Dropout(p=0.5, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=500, out_features=50, bias=True)
    )
    (dropout): Dropout(p=0.5, inplace=False)
  ), weights = ((1, 1, 3, 100), (1,), (200, 1, 1, 100), (200,), (1, 1, 500, 100), (1,), (100, 1, 2, 100), (100,), (100, 1, 3, 100), (100,), (100, 1, 4, 100), (100,), (500, 500), (500,), (50, 500), (50,)), parameters = 436,352 (Trainable)
  (DAttn_RatingPred): DAttn_RatingPred(
    (uid_userOffset): Embedding(541405, 1)
    (iid_itemOffset): Embedding(106040, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (541405, 1), (106040, 1)), parameters = 647,446 (Trainable)
)
========================================================================================================================

[Epoch 1/10] Training Loss: 1.04205	Elapsed Time: 606.02s (0:10:06)
[Epoch 1] [Dev]  MSE: 1.24398, MAE: 0.84870
[Epoch 1] [Test] MSE: 1.26193, MAE: 0.85008

*** MODEL has obtained the best DEV MSE of 1.24398 so far!
*** The Best MODEL saved to "./__saved_models__/Movies_and_TV - DAttn/Movies_and_TV_DAttn_1234.pth"

[Epoch 2/10] Training Loss: 0.82932	Elapsed Time: 1,230.31s (0:20:30)
[Epoch 2] [Dev]  MSE: 1.29148, MAE: 0.82098
[Epoch 2] [Test] MSE: 1.30949, MAE: 0.82200

[Epoch 3/10] Training Loss: 0.73972	Elapsed Time: 1,854.73s (0:30:54)
[Epoch 3] [Dev]  MSE: 1.25126, MAE: 0.81189
[Epoch 3] [Test] MSE: 1.27167, MAE: 0.81504

[Epoch 4/10] Training Loss: 0.68250	Elapsed Time: 2,479.17s (0:41:19)
[Epoch 4] [Dev]  MSE: 1.18269, MAE: 0.78151
[Epoch 4] [Test] MSE: 1.19483, MAE: 0.78281

*** MODEL has obtained the best DEV MSE of 1.18269 so far!
*** The Best MODEL saved to "./__saved_models__/Movies_and_TV - DAttn/Movies_and_TV_DAttn_1234.pth"

[Epoch 5/10] Training Loss: 0.62409	Elapsed Time: 3,104.02s (0:51:44)
[Epoch 5] [Dev]  MSE: 1.18008, MAE: 0.80230
[Epoch 5] [Test] MSE: 1.19549, MAE: 0.80481

*** MODEL has obtained the best DEV MSE of 1.18008 so far!
*** The Best MODEL saved to "./__saved_models__/Movies_and_TV - DAttn/Movies_and_TV_DAttn_1234.pth"

[Epoch 6/10] Training Loss: 0.60538	Elapsed Time: 3,729.59s (1:02:09)
[Epoch 6] [Dev]  MSE: 1.21886, MAE: 0.80629
[Epoch 6] [Test] MSE: 1.23463, MAE: 0.80868

[Epoch 7/10] Training Loss: 0.55281	Elapsed Time: 4,354.72s (1:12:34)
[Epoch 7] [Dev]  MSE: 1.21094, MAE: 0.79621
[Epoch 7] [Test] MSE: 1.22684, MAE: 0.79877

[Epoch 8/10] Training Loss: 0.52735	Elapsed Time: 4,979.57s (1:22:59)
[Epoch 8] [Dev]  MSE: 1.22085, MAE: 0.80093
[Epoch 8] [Test] MSE: 1.23783, MAE: 0.80432

[Epoch 9/10] Training Loss: 0.48955	Elapsed Time: 5,604.22s (1:33:24)
[Epoch 9] [Dev]  MSE: 1.23622, MAE: 0.81050
[Epoch 9] [Test] MSE: 1.25526, MAE: 0.81456

[Epoch 10/10] Training Loss: 0.46521	Elapsed Time: 6,228.68s (1:43:48)
[Epoch 10] [Dev]  MSE: 1.30881, MAE: 0.82792
[Epoch 10] [Test] MSE: 1.33130, MAE: 0.83230
*** The Last MODEL saved to "./__saved_models__/Movies_and_TV - DAttn/Movies_and_TV_DAttn_1234_10.pth"

[Training Loss]
[1.04205, 0.82932, 0.73972, 0.6825, 0.62409, 0.60538, 0.55281, 0.52735, 0.48955, 0.46521]

[Dev MSE]
[1.24398, 1.29148, 1.25126, 1.18269, 1.18008, 1.21886, 1.21094, 1.22085, 1.23622, 1.30881]
[Test MSE]
[1.26193, 1.30949, 1.27167, 1.19483, 1.19549, 1.23463, 1.22684, 1.23783, 1.25526, 1.3313]
[Test MAE]
[0.85008, 0.822, 0.81504, 0.78281, 0.80481, 0.80868, 0.79877, 0.80432, 0.81456, 0.8323]


Best Dev MSE: 1.18008 (Obtained during Evaluation #5)
Test MSE: 1.19549, Test MAE: 0.80481

End of Program! Elapsed Time: 6,290.39s (1:44:50)
