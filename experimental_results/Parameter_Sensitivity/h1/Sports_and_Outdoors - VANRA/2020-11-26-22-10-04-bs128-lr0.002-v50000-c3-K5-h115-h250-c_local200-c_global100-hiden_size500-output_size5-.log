========================================================================================================================
  ARL_lr: 0.01
  ARL_path: 
  batch_size: 128
  channels_global: 100
  channels_local: 200
  command: -d Sports_and_Outdoors -m VANRA -e 5 -dr 0.9 -WED 300 -p 1 -v 50000 -K 5 -h1 15 -kernel_list 3 -output_size 5 -rs 1234 -gpu 0 -vb 1 -sm Sports_and_Outdoors_VANRA
  ctx_win_size: 3
  dataset: Sports_and_Outdoors
  disable_initial_eval: 0
  dropout_rate: 0.9
  epochs: 5
  filters_num: 100
  gpu: 0
  h1: 15
  h2: 50
  hidden_size: 500
  input_dir: ./datasets/Sports_and_Outdoors/
  kernel_list: [3]
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  max_vis_len: 500
  model: VANRA
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Sports_and_Outdoors - VANRA/
  output_size: 5
  pretrained_src: 1
  random_seed: 1234
  save_model: Sports_and_Outdoors_VANRA
  use_cuda: True
  verbose: 1
  vocab_size: 50000
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 645,026, # of Items: 221,569

Creating model (Selected Model: VANRA)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 8.14s (0.14 minute)

Loading uid_userDoc from "./datasets/Sports_and_Outdoors/Sports_and_Outdoors_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (645026, 500)]

Loading iid_itemDoc from "./datasets/Sports_and_Outdoors/Sports_and_Outdoors_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (221569, 500)]

Loading pretrained word embeddings from "./datasets/Sports_and_Outdoors/Sports_and_Outdoors_wed300_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (50002, 300)]

Loading uid_userVis from "./datasets/Sports_and_Outdoors/Sports_and_Outdoors_uid_userVis.npy"..
uid_userVis loaded! [uid_userVis: (645026, 500)]

Loading iid_itemVis from "./datasets/Sports_and_Outdoors/Sports_and_Outdoors_iid_itemVis.npy"..
iid_itemVis loaded! [iid_itemVis: (221569, 500)]

Initialization Complete.. Elapsed Time: 65.33s (1.09 minutes)

Train/Dev/Test splits loaded! |TRAIN|: 800,000, |DEV|: 25,665, |TEST|: 25,738
Train/Dev/Test splits loaded! Elapsed Time: 65.60s (1.09 minutes)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 16.95181, MAE: 3.95120

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 16.97523, MAE: 3.95494

Initial Evaluation Complete.. Elapsed Time: 70.54s (1.18 minutes)

Parameters with L2 Regularization (Regularization Strength: 1e-06):
VANRA_RatingPred.uid_userOffset.weight, VANRA_RatingPred.iid_itemOffset.weight

Optimizer: Adam, Loss Function: MSELoss

Model Size: 882,496,216
# of Trainable Parameters: 900,616
VANRA (
  (uid_userDoc): Embedding(645026, 500), weights = ((645026, 500),), parameters = 322,513,000
  (iid_itemDoc): Embedding(221569, 500), weights = ((221569, 500),), parameters = 110,784,500
  (wid_wEmbed): Embedding(50002, 300), weights = ((50002, 300),), parameters = 15,000,600
  (uid_userVis): Embedding(645026, 500), weights = ((645026, 500),), parameters = 322,513,000
  (iid_itemVis): Embedding(221569, 500), weights = ((221569, 500),), parameters = 110,784,500
  (MSANR_ARL): MSANR_ARL(
    (aspEmbed): ModuleList(
      (0): Embedding(5, 45)
    )
    (filterEmbed): Embedding(5, 15)
    (aspProj): Parameter(5, 300, 15)
  ), weights = ((5, 300, 15), (5, 45), (5, 15)), parameters = 22,800 (Trainable)
  (VANRA_VRL): VANRA_VRL(
    (fcLayer): Sequential(
      (0): Dropout(p=0.9, inplace=False)
      (1): Linear(in_features=500, out_features=5, bias=True)
    )
    (visProj): Parameter(500, 15)
  ), weights = ((500, 15), (5, 500), (5,)), parameters = 10,005 (Trainable)
  (VANRA_RatingPred): VANRA_RatingPred(
    (uid_userOffset): Embedding(645026, 1)
    (iid_itemOffset): Embedding(221569, 1)
    (fcLayer1): Sequential(
      (0): Linear(in_features=80, out_features=15, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.9, inplace=False)
    )
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (645026, 1), (221569, 1), (15, 80), (15,)), parameters = 867,811 (Trainable)
)
========================================================================================================================

[Epoch 1/5] Training Loss: 5.09211	Elapsed Time: 157.49s (0:02:37)
[Epoch 1] [Dev]  MSE: 1.12509, MAE: 0.82545
[Epoch 1] [Test] MSE: 1.11825, MAE: 0.82534

*** MODEL has obtained the best DEV MSE of 1.12509 so far!
*** The Best MODEL saved to "./__saved_models__/Sports_and_Outdoors - VANRA/Sports_and_Outdoors_VANRA_1234.pth"

[Epoch 2/5] Training Loss: 1.32816	Elapsed Time: 320.00s (0:05:19)
[Epoch 2] [Dev]  MSE: 1.08829, MAE: 0.79313
[Epoch 2] [Test] MSE: 1.08245, MAE: 0.79239

*** MODEL has obtained the best DEV MSE of 1.08829 so far!
*** The Best MODEL saved to "./__saved_models__/Sports_and_Outdoors - VANRA/Sports_and_Outdoors_VANRA_1234.pth"

[Epoch 3/5] Training Loss: 1.19839	Elapsed Time: 482.50s (0:08:02)
[Epoch 3] [Dev]  MSE: 1.08437, MAE: 0.77946
[Epoch 3] [Test] MSE: 1.07801, MAE: 0.77829

*** MODEL has obtained the best DEV MSE of 1.08437 so far!
*** The Best MODEL saved to "./__saved_models__/Sports_and_Outdoors - VANRA/Sports_and_Outdoors_VANRA_1234.pth"

[Epoch 4/5] Training Loss: 1.11685	Elapsed Time: 645.02s (0:10:45)
[Epoch 4] [Dev]  MSE: 1.08896, MAE: 0.78175
[Epoch 4] [Test] MSE: 1.08381, MAE: 0.78055

[Epoch 5/5] Training Loss: 1.06264	Elapsed Time: 807.40s (0:13:27)
[Epoch 5] [Dev]  MSE: 1.09407, MAE: 0.78224
[Epoch 5] [Test] MSE: 1.09006, MAE: 0.78109
*** The Last MODEL saved to "./__saved_models__/Sports_and_Outdoors - VANRA/Sports_and_Outdoors_VANRA_1234_5.pth"

[Training Loss]
[5.09211, 1.32816, 1.19839, 1.11685, 1.06264]

[Dev MSE]
[1.12509, 1.08829, 1.08437, 1.08896, 1.09407]
[Test MSE]
[1.11825, 1.08245, 1.07801, 1.08381, 1.09006]
[Test MAE]
[0.82534, 0.79239, 0.77829, 0.78055, 0.78109]


Best Dev MSE: 1.08437 (Obtained during Evaluation #3)
Test MSE: 1.07801, Test MAE: 0.77829

End of Program! Elapsed Time: 882.79s (0:14:42)
