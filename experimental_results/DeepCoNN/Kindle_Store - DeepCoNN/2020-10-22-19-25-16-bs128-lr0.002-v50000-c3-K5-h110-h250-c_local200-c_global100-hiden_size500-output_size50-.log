========================================================================================================================
  ARL_lr: 0.01
  ARL_path: 
  batch_size: 128
  channels_global: 100
  channels_local: 200
  command: -d Kindle_Store -m DeepCoNN -e 10 -dr 0.5 -p 1 -v 50000 -K 5 -h1 10 -h2 50 -filters_num 100 -output_size 50 -rs 1234 -gpu 0 -vb 1 -sm Kindle_Store_DeepCoNN
  ctx_win_size: 3
  dataset: Kindle_Store
  disable_initial_eval: 0
  dropout_rate: 0.5
  epochs: 10
  filters_num: 100
  gpu: 0
  h1: 10
  h2: 50
  hidden_size: 500
  input_dir: ./datasets/Kindle_Store/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  max_vis_len: 500
  model: DeepCoNN
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Kindle_Store - DeepCoNN/
  output_size: 50
  pretrained_src: 1
  random_seed: 1234
  save_model: Kindle_Store_DeepCoNN
  use_cuda: True
  verbose: 1
  vocab_size: 50000
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 488,920, # of Items: 232,137

Creating model (Selected Model: DeepCoNN)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 4.16s (0.07 minute)

Loading uid_userDoc from "./datasets/Kindle_Store/Kindle_Store_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (488920, 500)]

Loading iid_itemDoc from "./datasets/Kindle_Store/Kindle_Store_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (232137, 500)]

Loading pretrained word embeddings from "./datasets/Kindle_Store/Kindle_Store_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (50002, 300)]

Initialization Complete.. Elapsed Time: 23.56s (0.39 minute)

Train/Dev/Test splits loaded! |TRAIN|: 800,000, |DEV|: 43,894, |TEST|: 43,882
Train/Dev/Test splits loaded! Elapsed Time: 23.81s (0.40 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 15.05577, MAE: 3.74561

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 15.10074, MAE: 3.75204

Initial Evaluation Complete.. Elapsed Time: 31.01s (0.52 minute)

Optimizer: Adam, Loss Function: MSELoss

Model Size: 376,440,458
# of Trainable Parameters: 911,358
DeepCoNN (
  (uid_userDoc): Embedding(488920, 500), weights = ((488920, 500),), parameters = 244,460,000
  (iid_itemDoc): Embedding(232137, 500), weights = ((232137, 500),), parameters = 116,068,500
  (wid_wEmbed): Embedding(50002, 300), weights = ((50002, 300),), parameters = 15,000,600
  (user_CNN): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1)), weights = ((100, 1, 3, 300), (100,)), parameters = 90,100 (Trainable)
  (item_CNN): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1)), weights = ((100, 1, 3, 300), (100,)), parameters = 90,100 (Trainable)
  (user_fcLayer): Linear(in_features=100, out_features=50, bias=True), weights = ((50, 100), (50,)), parameters = 5,050 (Trainable)
  (item_fcLayer): Linear(in_features=100, out_features=50, bias=True), weights = ((50, 100), (50,)), parameters = 5,050 (Trainable)
  (userDropout): Dropout(p=0.5, inplace=False), weights = (), parameters = 0
  (itemDropout): Dropout(p=0.5, inplace=False), weights = (), parameters = 0
  (DeepCoNN_RatingPred): DeepCoNN_RatingPred(
    (uid_userOffset): Embedding(488920, 1)
    (iid_itemOffset): Embedding(232137, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (488920, 1), (232137, 1)), parameters = 721,058 (Trainable)
)
========================================================================================================================

[Epoch 1/10] Training Loss: 1.04579	Elapsed Time: 123.86s (0:02:03)
[Epoch 1] [Dev]  MSE: 0.92585, MAE: 0.67610
[Epoch 1] [Test] MSE: 0.92276, MAE: 0.67512

*** MODEL has obtained the best DEV MSE of 0.92585 so far!
*** The Best MODEL saved to "./__saved_models__/Kindle_Store - DeepCoNN/Kindle_Store_DeepCoNN_1234.pth"

[Epoch 2/10] Training Loss: 0.63881	Elapsed Time: 254.90s (0:04:14)
[Epoch 2] [Dev]  MSE: 0.84859, MAE: 0.64147
[Epoch 2] [Test] MSE: 0.84653, MAE: 0.64150

*** MODEL has obtained the best DEV MSE of 0.84859 so far!
*** The Best MODEL saved to "./__saved_models__/Kindle_Store - DeepCoNN/Kindle_Store_DeepCoNN_1234.pth"

[Epoch 3/10] Training Loss: 0.55727	Elapsed Time: 385.98s (0:06:25)
[Epoch 3] [Dev]  MSE: 0.87375, MAE: 0.66338
[Epoch 3] [Test] MSE: 0.86894, MAE: 0.66353

[Epoch 4/10] Training Loss: 0.49995	Elapsed Time: 516.98s (0:08:36)
[Epoch 4] [Dev]  MSE: 0.89742, MAE: 0.67689
[Epoch 4] [Test] MSE: 0.89465, MAE: 0.67626

[Epoch 5/10] Training Loss: 0.45370	Elapsed Time: 648.08s (0:10:48)
[Epoch 5] [Dev]  MSE: 0.88441, MAE: 0.66548
[Epoch 5] [Test] MSE: 0.87950, MAE: 0.66512

[Epoch 6/10] Training Loss: 0.41532	Elapsed Time: 779.10s (0:12:59)
[Epoch 6] [Dev]  MSE: 0.88662, MAE: 0.66111
[Epoch 6] [Test] MSE: 0.88466, MAE: 0.66177

[Epoch 7/10] Training Loss: 0.38405	Elapsed Time: 910.06s (0:15:10)
[Epoch 7] [Dev]  MSE: 0.88209, MAE: 0.66573
[Epoch 7] [Test] MSE: 0.88222, MAE: 0.66771

[Epoch 8/10] Training Loss: 0.35809	Elapsed Time: 1,041.05s (0:17:21)
[Epoch 8] [Dev]  MSE: 0.87917, MAE: 0.66538
[Epoch 8] [Test] MSE: 0.87799, MAE: 0.66723

[Epoch 9/10] Training Loss: 0.33662	Elapsed Time: 1,172.06s (0:19:32)
[Epoch 9] [Dev]  MSE: 0.89639, MAE: 0.66190
[Epoch 9] [Test] MSE: 0.89210, MAE: 0.66297

[Epoch 10/10] Training Loss: 0.31740	Elapsed Time: 1,303.06s (0:21:43)
[Epoch 10] [Dev]  MSE: 0.91507, MAE: 0.67016
[Epoch 10] [Test] MSE: 0.91065, MAE: 0.67097
*** The Last MODEL saved to "./__saved_models__/Kindle_Store - DeepCoNN/Kindle_Store_DeepCoNN_1234_10.pth"

[Training Loss]
[1.04579, 0.63881, 0.55727, 0.49995, 0.4537, 0.41532, 0.38405, 0.35809, 0.33662, 0.3174]

[Dev MSE]
[0.92585, 0.84859, 0.87375, 0.89742, 0.88441, 0.88662, 0.88209, 0.87917, 0.89639, 0.91507]
[Test MSE]
[0.92276, 0.84653, 0.86894, 0.89465, 0.8795, 0.88466, 0.88222, 0.87799, 0.8921, 0.91065]
[Test MAE]
[0.67512, 0.6415, 0.66353, 0.67626, 0.66512, 0.66177, 0.66771, 0.66723, 0.66297, 0.67097]


Best Dev MSE: 0.84859 (Obtained during Evaluation #2)
Test MSE: 0.84653, Test MAE: 0.64150

End of Program! Elapsed Time: 1,341.17s (0:22:21)
