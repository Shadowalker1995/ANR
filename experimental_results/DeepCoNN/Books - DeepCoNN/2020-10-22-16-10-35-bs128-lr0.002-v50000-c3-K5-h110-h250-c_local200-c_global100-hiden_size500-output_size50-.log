========================================================================================================================
  ARL_lr: 0.01
  ARL_path: 
  batch_size: 128
  channels_global: 100
  channels_local: 200
  command: -d Books -m DeepCoNN -e 10 -dr 0.5 -p 1 -v 50000 -K 5 -h1 10 -h2 50 -filters_num 100 -output_size 50 -rs 1234 -gpu 0 -vb 1 -sm Books_DeepCoNN
  ctx_win_size: 3
  dataset: Books
  disable_initial_eval: 0
  dropout_rate: 0.5
  epochs: 10
  filters_num: 100
  gpu: 0
  h1: 10
  h2: 50
  hidden_size: 500
  input_dir: ./datasets/Books/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  max_vis_len: 500
  model: DeepCoNN
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Books - DeepCoNN/
  output_size: 50
  pretrained_src: 1
  random_seed: 1234
  save_model: Books_DeepCoNN
  use_cuda: True
  verbose: 1
  vocab_size: 50000
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 621,433, # of Items: 390,310

Creating model (Selected Model: DeepCoNN)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 5.32s (0.09 minute)

Loading uid_userDoc from "./datasets/Books/Books_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (621433, 500)]

Loading iid_itemDoc from "./datasets/Books/Books_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (390310, 500)]

Loading pretrained word embeddings from "./datasets/Books/Books_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (50002, 300)]

Initialization Complete.. Elapsed Time: 41.18s (0.69 minute)

Train/Dev/Test splits loaded! |TRAIN|: 800,000, |DEV|: 20,828, |TEST|: 21,246
Train/Dev/Test splits loaded! Elapsed Time: 41.44s (0.69 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 15.81737, MAE: 3.83390

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 15.95517, MAE: 3.85779

Initial Evaluation Complete.. Elapsed Time: 44.96s (0.75 minute)

Optimizer: Adam, Loss Function: MSELoss

Model Size: 522,074,144
# of Trainable Parameters: 1,202,044
DeepCoNN (
  (uid_userDoc): Embedding(621433, 500), weights = ((621433, 500),), parameters = 310,716,500
  (iid_itemDoc): Embedding(390310, 500), weights = ((390310, 500),), parameters = 195,155,000
  (wid_wEmbed): Embedding(50002, 300), weights = ((50002, 300),), parameters = 15,000,600
  (user_CNN): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1)), weights = ((100, 1, 3, 300), (100,)), parameters = 90,100 (Trainable)
  (item_CNN): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1)), weights = ((100, 1, 3, 300), (100,)), parameters = 90,100 (Trainable)
  (user_fcLayer): Linear(in_features=100, out_features=50, bias=True), weights = ((50, 100), (50,)), parameters = 5,050 (Trainable)
  (item_fcLayer): Linear(in_features=100, out_features=50, bias=True), weights = ((50, 100), (50,)), parameters = 5,050 (Trainable)
  (userDropout): Dropout(p=0.5, inplace=False), weights = (), parameters = 0
  (itemDropout): Dropout(p=0.5, inplace=False), weights = (), parameters = 0
  (DeepCoNN_RatingPred): DeepCoNN_RatingPred(
    (uid_userOffset): Embedding(621433, 1)
    (iid_itemOffset): Embedding(390310, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (621433, 1), (390310, 1)), parameters = 1,011,744 (Trainable)
)
========================================================================================================================

[Epoch 1/10] Training Loss: 1.05845	Elapsed Time: 123.88s (0:02:03)
[Epoch 1] [Dev]  MSE: 1.11283, MAE: 0.78787
[Epoch 1] [Test] MSE: 1.08253, MAE: 0.77977

*** MODEL has obtained the best DEV MSE of 1.11283 so far!
*** The Best MODEL saved to "./__saved_models__/Books - DeepCoNN/Books_DeepCoNN_1234.pth"

[Epoch 2/10] Training Loss: 0.63150	Elapsed Time: 251.33s (0:04:11)
[Epoch 2] [Dev]  MSE: 1.11315, MAE: 0.77325
[Epoch 2] [Test] MSE: 1.07971, MAE: 0.76372

[Epoch 3/10] Training Loss: 0.53558	Elapsed Time: 378.75s (0:06:18)
[Epoch 3] [Dev]  MSE: 1.06187, MAE: 0.75347
[Epoch 3] [Test] MSE: 1.02860, MAE: 0.74349

*** MODEL has obtained the best DEV MSE of 1.06187 so far!
*** The Best MODEL saved to "./__saved_models__/Books - DeepCoNN/Books_DeepCoNN_1234.pth"

[Epoch 4/10] Training Loss: 0.46554	Elapsed Time: 506.19s (0:08:26)
[Epoch 4] [Dev]  MSE: 1.08066, MAE: 0.76187
[Epoch 4] [Test] MSE: 1.05815, MAE: 0.75780

[Epoch 5/10] Training Loss: 0.40937	Elapsed Time: 633.60s (0:10:33)
[Epoch 5] [Dev]  MSE: 1.13183, MAE: 0.78248
[Epoch 5] [Test] MSE: 1.10421, MAE: 0.77388

[Epoch 6/10] Training Loss: 0.36319	Elapsed Time: 761.02s (0:12:41)
[Epoch 6] [Dev]  MSE: 1.13492, MAE: 0.76145
[Epoch 6] [Test] MSE: 1.10719, MAE: 0.75234

[Epoch 7/10] Training Loss: 0.32498	Elapsed Time: 888.44s (0:14:48)
[Epoch 7] [Dev]  MSE: 1.13830, MAE: 0.76343
[Epoch 7] [Test] MSE: 1.10747, MAE: 0.75407

[Epoch 8/10] Training Loss: 0.29346	Elapsed Time: 1,015.86s (0:16:55)
[Epoch 8] [Dev]  MSE: 1.14116, MAE: 0.77107
[Epoch 8] [Test] MSE: 1.10763, MAE: 0.76288

[Epoch 9/10] Training Loss: 0.26717	Elapsed Time: 1,143.27s (0:19:03)
[Epoch 9] [Dev]  MSE: 1.17171, MAE: 0.77953
[Epoch 9] [Test] MSE: 1.13868, MAE: 0.77177

[Epoch 10/10] Training Loss: 0.24457	Elapsed Time: 1,270.72s (0:21:10)
[Epoch 10] [Dev]  MSE: 1.17831, MAE: 0.78261
[Epoch 10] [Test] MSE: 1.15074, MAE: 0.77650
*** The Last MODEL saved to "./__saved_models__/Books - DeepCoNN/Books_DeepCoNN_1234_10.pth"

[Training Loss]
[1.05845, 0.6315, 0.53558, 0.46554, 0.40937, 0.36319, 0.32498, 0.29346, 0.26717, 0.24457]

[Dev MSE]
[1.11283, 1.11315, 1.06187, 1.08066, 1.13183, 1.13492, 1.1383, 1.14116, 1.17171, 1.17831]
[Test MSE]
[1.08253, 1.07971, 1.0286, 1.05815, 1.10421, 1.10719, 1.10747, 1.10763, 1.13868, 1.15074]
[Test MAE]
[0.77977, 0.76372, 0.74349, 0.7578, 0.77388, 0.75234, 0.75407, 0.76288, 0.77177, 0.7765]


Best Dev MSE: 1.06187 (Obtained during Evaluation #3)
Test MSE: 1.02860, Test MAE: 0.74349

End of Program! Elapsed Time: 1,319.09s (0:21:59)
