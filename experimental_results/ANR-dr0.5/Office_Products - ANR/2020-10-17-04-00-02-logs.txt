========================================================================================================================
  ARL_lr: 0.01
  ARL_path: Office_Products_ANRS_1337
  batch_size: 128
  command: -d Office_Products -m ANR -e 15 -p 1 -v 50000 -rs 5678 -gpu 0 -vb 1 -sm Office_Products_ANR -ARL_path Office_Products_ANRS_1337
  ctx_win_size: 3
  dataset: Office_Products
  disable_initial_eval: 0
  dropout_rate: 0.5
  epochs: 15
  gpu: 0
  h1: 10
  h2: 50
  input_dir: ./datasets/Office_Products/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  model: ANR
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Office_Products - ANR/
  pretrained_src: 1
  random_seed: 5678
  save_model: Office_Products_ANR
  use_cuda: True
  verbose: 1
  vocab_size: 50000
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 628,512, # of Items: 105,406

Creating model (Selected Model: ANR)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 4.20s (0.07 minute)

Loading uid_userDoc from "./datasets/Office_Products/Office_Products_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (628512, 500)]

Loading iid_itemDoc from "./datasets/Office_Products/Office_Products_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (105406, 500)]

Loading pretrained word embeddings from "./datasets/Office_Products/Office_Products_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (50002, 300)]

Loading pretrained ARL weights of "ANR" for dataset "Office_Products" from "./__saved_models__/Office_Products - ANRS/Office_Products_ANRS_1337.pth"!
Loading pretrained ARL weights on GPU "0"!

Loaded pretrained model states:

	shared_ANR_ARL.aspProj
	shared_ANR_ARL.aspEmbed.weight

Pretrained model states transferred to current model!

*** "shared_ANR_ARL.aspProj, shared_ANR_ARL.aspEmbed.weight" are FINE-TUNED!! ***


Initialization Complete.. Elapsed Time: 28.72s (0.48 minute)

Train/Dev/Test splits loaded! |TRAIN|: 800,000, |DEV|: 30,765, |TEST|: 30,933
Train/Dev/Test splits loaded! Elapsed Time: 28.97s (0.48 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 2.31115, MAE: 1.32937

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 2.29683, MAE: 1.32537

Initial Evaluation Complete.. Elapsed Time: 34.15s (0.57 minute)

Parameters that are fine-tuned using a smaller LR (LR: 2e-05):
shared_ANR_ARL.aspProj, shared_ANR_ARL.aspEmbed.weight

Parameters with L2 Regularization (Regularization Strength: 1e-06):
ANR_RatingPred.uid_userOffset.weight, ANR_RatingPred.iid_itemOffset.weight

Optimizer: Adam, Loss Function: MSELoss

Model Size: 382,709,869
# of Trainable Parameters: 750,269
ANR (
  (uid_userDoc): Embedding(628512, 500), weights = ((628512, 500),), parameters = 314,256,000
  (iid_itemDoc): Embedding(105406, 500), weights = ((105406, 500),), parameters = 52,703,000
  (wid_wEmbed): Embedding(50002, 300), weights = ((50002, 300),), parameters = 15,000,600
  (shared_ANR_ARL): ANR_ARL(
    (aspEmbed): Embedding(5, 30)
    (aspProj): Parameter(5, 300, 10)
  ), weights = ((5, 300, 10), (5, 30)), parameters = 15,150 (Trainable)
  (ANR_AIE): ANR_AIE(  (W_a): Parameter(10, 10)
    (W_u): Parameter(50, 10)
    (w_hu): Parameter(50, 1)
    (W_i): Parameter(50, 10)
    (w_hi): Parameter(50, 1)
  ), weights = ((10, 10), (50, 10), (50, 1), (50, 10), (50, 1)), parameters = 1,200 (Trainable)
  (ANR_RatingPred): ANR_RatingPred(
    (userAspRepDropout): Dropout(p=0.5, inplace=False)
    (itemAspRepDropout): Dropout(p=0.5, inplace=False)
    (uid_userOffset): Embedding(628512, 1)
    (iid_itemOffset): Embedding(105406, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (628512, 1), (105406, 1)), parameters = 733,919 (Trainable)
)
========================================================================================================================

[Epoch 1/15] Training Loss: 1.35572	Elapsed Time: 148.87s (0:02:28)
[Epoch 1] [Dev]  MSE: 1.47636, MAE: 0.88349
[Epoch 1] [Test] MSE: 1.47003, MAE: 0.88572

*** MODEL has obtained the best DEV MSE of 1.47636 so far!
*** MODEL saved to "./__saved_models__/Office_Products - ANR/Office_Products_ANR_5678.pth"

[Epoch 2/15] Training Loss: 1.05429	Elapsed Time: 302.75s (0:05:02)
[Epoch 2] [Dev]  MSE: 1.43868, MAE: 0.90896
[Epoch 2] [Test] MSE: 1.42648, MAE: 0.90694

*** MODEL has obtained the best DEV MSE of 1.43868 so far!
*** MODEL saved to "./__saved_models__/Office_Products - ANR/Office_Products_ANR_5678.pth"

[Epoch 3/15] Training Loss: 0.97653	Elapsed Time: 456.63s (0:07:36)
[Epoch 3] [Dev]  MSE: 1.45504, MAE: 0.90594
[Epoch 3] [Test] MSE: 1.43780, MAE: 0.90217

[Epoch 4/15] Training Loss: 0.92414	Elapsed Time: 610.56s (0:10:10)
[Epoch 4] [Dev]  MSE: 1.42165, MAE: 0.88249
[Epoch 4] [Test] MSE: 1.40209, MAE: 0.87725

*** MODEL has obtained the best DEV MSE of 1.42165 so far!
*** MODEL saved to "./__saved_models__/Office_Products - ANR/Office_Products_ANR_5678.pth"

[Epoch 5/15] Training Loss: 0.88925	Elapsed Time: 764.36s (0:12:44)
[Epoch 5] [Dev]  MSE: 1.42208, MAE: 0.87180
[Epoch 5] [Test] MSE: 1.40213, MAE: 0.86588

[Epoch 6/15] Training Loss: 0.86279	Elapsed Time: 918.13s (0:15:18)
[Epoch 6] [Dev]  MSE: 1.42660, MAE: 0.87389
[Epoch 6] [Test] MSE: 1.40602, MAE: 0.86818

[Epoch 7/15] Training Loss: 0.84253	Elapsed Time: 1,071.99s (0:17:51)
[Epoch 7] [Dev]  MSE: 1.43446, MAE: 0.87693
[Epoch 7] [Test] MSE: 1.41329, MAE: 0.87143

[Epoch 8/15] Training Loss: 0.83050	Elapsed Time: 1,225.89s (0:20:25)
[Epoch 8] [Dev]  MSE: 1.44249, MAE: 0.87796
[Epoch 8] [Test] MSE: 1.41894, MAE: 0.87120

[Epoch 9/15] Training Loss: 0.81863	Elapsed Time: 1,379.73s (0:22:59)
[Epoch 9] [Dev]  MSE: 1.45788, MAE: 0.87120
[Epoch 9] [Test] MSE: 1.43524, MAE: 0.86453

[Epoch 10/15] Training Loss: 0.80878	Elapsed Time: 1,533.69s (0:25:33)
[Epoch 10] [Dev]  MSE: 1.44584, MAE: 0.86950
[Epoch 10] [Test] MSE: 1.42418, MAE: 0.86262

[Epoch 11/15] Training Loss: 0.80346	Elapsed Time: 1,687.52s (0:28:07)
[Epoch 11] [Dev]  MSE: 1.43738, MAE: 0.87659
[Epoch 11] [Test] MSE: 1.41672, MAE: 0.87063

[Epoch 12/15] Training Loss: 0.79606	Elapsed Time: 1,841.38s (0:30:41)
[Epoch 12] [Dev]  MSE: 1.48589, MAE: 0.86847
[Epoch 12] [Test] MSE: 1.46226, MAE: 0.86230

[Epoch 13/15] Training Loss: 0.79275	Elapsed Time: 1,995.17s (0:33:15)
[Epoch 13] [Dev]  MSE: 1.45710, MAE: 0.88424
[Epoch 13] [Test] MSE: 1.43542, MAE: 0.87763

[Epoch 14/15] Training Loss: 0.78938	Elapsed Time: 2,148.97s (0:35:48)
[Epoch 14] [Dev]  MSE: 1.46518, MAE: 0.87384
[Epoch 14] [Test] MSE: 1.44126, MAE: 0.86681

[Epoch 15/15] Training Loss: 0.78628	Elapsed Time: 2,302.76s (0:38:22)
[Epoch 15] [Dev]  MSE: 1.46338, MAE: 0.88967
[Epoch 15] [Test] MSE: 1.43829, MAE: 0.88264

[Training Loss]
[1.35572, 1.05429, 0.97653, 0.92414, 0.88925, 0.86279, 0.84253, 0.8305, 0.81863, 0.80878, 0.80346, 0.79606, 0.79275, 0.78938, 0.78628]

[Dev MSE]
[1.47636, 1.43868, 1.45504, 1.42165, 1.42208, 1.4266, 1.43446, 1.44249, 1.45788, 1.44584, 1.43738, 1.48589, 1.4571, 1.46518, 1.46338]
[Test MSE]
[1.47003, 1.42648, 1.4378, 1.40209, 1.40213, 1.40602, 1.41329, 1.41894, 1.43524, 1.42418, 1.41672, 1.46226, 1.43542, 1.44126, 1.43829]
[Test MAE]
[0.88572, 0.90694, 0.90217, 0.87725, 0.86588, 0.86818, 0.87143, 0.8712, 0.86453, 0.86262, 0.87063, 0.8623, 0.87763, 0.86681, 0.88264]


Best Dev MSE: 1.42165 (Obtained during Evaluation #4)
Test MSE: 1.40209, Test MAE: 0.87725

End of Program! Elapsed Time: 2,341.84s (0:39:01)
