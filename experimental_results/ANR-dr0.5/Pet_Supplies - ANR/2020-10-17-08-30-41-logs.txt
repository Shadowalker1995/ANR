========================================================================================================================
  ARL_lr: 0.01
  ARL_path: Pet_Supplies_ANRS_1337
  batch_size: 128
  command: -d Pet_Supplies -m ANR -e 15 -p 1 -v 50000 -rs 1357 -gpu 0 -vb 1 -sm Pet_Supplies_ANR -ARL_path Pet_Supplies_ANRS_1337
  ctx_win_size: 3
  dataset: Pet_Supplies
  disable_initial_eval: 0
  dropout_rate: 0.5
  epochs: 15
  gpu: 0
  h1: 10
  h2: 50
  input_dir: ./datasets/Pet_Supplies/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  model: ANR
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Pet_Supplies - ANR/
  pretrained_src: 1
  random_seed: 1357
  save_model: Pet_Supplies_ANR
  use_cuda: True
  verbose: 1
  vocab_size: 50000
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 535,028, # of Items: 85,685

Creating model (Selected Model: ANR)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 3.76s (0.06 minute)

Loading uid_userDoc from "./datasets/Pet_Supplies/Pet_Supplies_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (535028, 500)]

Loading iid_itemDoc from "./datasets/Pet_Supplies/Pet_Supplies_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (85685, 500)]

Loading pretrained word embeddings from "./datasets/Pet_Supplies/Pet_Supplies_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (50002, 300)]

Loading pretrained ARL weights of "ANR" for dataset "Pet_Supplies" from "./__saved_models__/Pet_Supplies - ANRS/Pet_Supplies_ANRS_1337.pth"!
Loading pretrained ARL weights on GPU "0"!

Loaded pretrained model states:

	shared_ANR_ARL.aspProj
	shared_ANR_ARL.aspEmbed.weight

Pretrained model states transferred to current model!

*** "shared_ANR_ARL.aspProj, shared_ANR_ARL.aspEmbed.weight" are FINE-TUNED!! ***


Initialization Complete.. Elapsed Time: 5.06s (0.08 minute)

Train/Dev/Test splits loaded! |TRAIN|: 800,000, |DEV|: 46,037, |TEST|: 46,223
Train/Dev/Test splits loaded! Elapsed Time: 5.27s (0.09 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 3.89221, MAE: 1.80615

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 3.90508, MAE: 1.81017

Initial Evaluation Complete.. Elapsed Time: 12.85s (0.21 minute)

Parameters that are fine-tuned using a smaller LR (LR: 2e-05):
shared_ANR_ARL.aspProj, shared_ANR_ARL.aspEmbed.weight

Parameters with L2 Regularization (Regularization Strength: 1e-06):
ANR_RatingPred.uid_userOffset.weight, ANR_RatingPred.iid_itemOffset.weight

Optimizer: Adam, Loss Function: MSELoss

Model Size: 325,994,164
# of Trainable Parameters: 637,064
ANR (
  (uid_userDoc): Embedding(535028, 500), weights = ((535028, 500),), parameters = 267,514,000
  (iid_itemDoc): Embedding(85685, 500), weights = ((85685, 500),), parameters = 42,842,500
  (wid_wEmbed): Embedding(50002, 300), weights = ((50002, 300),), parameters = 15,000,600
  (shared_ANR_ARL): ANR_ARL(
    (aspEmbed): Embedding(5, 30)
    (aspProj): Parameter(5, 300, 10)
  ), weights = ((5, 300, 10), (5, 30)), parameters = 15,150 (Trainable)
  (ANR_AIE): ANR_AIE(  (W_a): Parameter(10, 10)
    (W_u): Parameter(50, 10)
    (w_hu): Parameter(50, 1)
    (W_i): Parameter(50, 10)
    (w_hi): Parameter(50, 1)
  ), weights = ((10, 10), (50, 10), (50, 1), (50, 10), (50, 1)), parameters = 1,200 (Trainable)
  (ANR_RatingPred): ANR_RatingPred(
    (userAspRepDropout): Dropout(p=0.5, inplace=False)
    (itemAspRepDropout): Dropout(p=0.5, inplace=False)
    (uid_userOffset): Embedding(535028, 1)
    (iid_itemOffset): Embedding(85685, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (535028, 1), (85685, 1)), parameters = 620,714 (Trainable)
)
========================================================================================================================

[Epoch 1/15] Training Loss: 1.69980	Elapsed Time: 148.65s (0:02:28)
[Epoch 1] [Dev]  MSE: 1.44119, MAE: 0.91661
[Epoch 1] [Test] MSE: 1.44923, MAE: 0.91915

*** MODEL has obtained the best DEV MSE of 1.44119 so far!
*** MODEL saved to "./__saved_models__/Pet_Supplies - ANR/Pet_Supplies_ANR_1357.pth"

[Epoch 2/15] Training Loss: 1.16959	Elapsed Time: 304.55s (0:05:04)
[Epoch 2] [Dev]  MSE: 1.43131, MAE: 0.94098
[Epoch 2] [Test] MSE: 1.44222, MAE: 0.94390

*** MODEL has obtained the best DEV MSE of 1.43131 so far!
*** MODEL saved to "./__saved_models__/Pet_Supplies - ANR/Pet_Supplies_ANR_1357.pth"

[Epoch 3/15] Training Loss: 1.07351	Elapsed Time: 460.43s (0:07:40)
[Epoch 3] [Dev]  MSE: 1.43869, MAE: 0.89801
[Epoch 3] [Test] MSE: 1.45020, MAE: 0.90100

[Epoch 4/15] Training Loss: 1.01402	Elapsed Time: 616.27s (0:10:16)
[Epoch 4] [Dev]  MSE: 1.45599, MAE: 0.89352
[Epoch 4] [Test] MSE: 1.46773, MAE: 0.89606

[Epoch 5/15] Training Loss: 0.97615	Elapsed Time: 772.14s (0:12:52)
[Epoch 5] [Dev]  MSE: 1.45667, MAE: 0.92207
[Epoch 5] [Test] MSE: 1.46811, MAE: 0.92481

[Epoch 6/15] Training Loss: 0.94801	Elapsed Time: 927.92s (0:15:27)
[Epoch 6] [Dev]  MSE: 1.43111, MAE: 0.91060
[Epoch 6] [Test] MSE: 1.44287, MAE: 0.91359

*** MODEL has obtained the best DEV MSE of 1.43111 so far!
*** MODEL saved to "./__saved_models__/Pet_Supplies - ANR/Pet_Supplies_ANR_1357.pth"

[Epoch 7/15] Training Loss: 0.92689	Elapsed Time: 1,084.02s (0:18:04)
[Epoch 7] [Dev]  MSE: 1.44219, MAE: 0.92708
[Epoch 7] [Test] MSE: 1.45620, MAE: 0.93090

[Epoch 8/15] Training Loss: 0.90904	Elapsed Time: 1,239.89s (0:20:39)
[Epoch 8] [Dev]  MSE: 1.45272, MAE: 0.90140
[Epoch 8] [Test] MSE: 1.46490, MAE: 0.90417

[Epoch 9/15] Training Loss: 0.89744	Elapsed Time: 1,395.84s (0:23:15)
[Epoch 9] [Dev]  MSE: 1.44853, MAE: 0.90436
[Epoch 9] [Test] MSE: 1.46157, MAE: 0.90750

[Epoch 10/15] Training Loss: 0.88869	Elapsed Time: 1,551.60s (0:25:51)
[Epoch 10] [Dev]  MSE: 1.46962, MAE: 0.89314
[Epoch 10] [Test] MSE: 1.48284, MAE: 0.89582

[Epoch 11/15] Training Loss: 0.87912	Elapsed Time: 1,707.43s (0:28:27)
[Epoch 11] [Dev]  MSE: 1.46855, MAE: 0.89468
[Epoch 11] [Test] MSE: 1.48040, MAE: 0.89713

[Epoch 12/15] Training Loss: 0.87235	Elapsed Time: 1,863.32s (0:31:03)
[Epoch 12] [Dev]  MSE: 1.47771, MAE: 0.89749
[Epoch 12] [Test] MSE: 1.48980, MAE: 0.89985

[Epoch 13/15] Training Loss: 0.86710	Elapsed Time: 2,019.20s (0:33:39)
[Epoch 13] [Dev]  MSE: 1.47047, MAE: 0.89949
[Epoch 13] [Test] MSE: 1.48303, MAE: 0.90183

[Epoch 14/15] Training Loss: 0.86392	Elapsed Time: 2,175.18s (0:36:15)
[Epoch 14] [Dev]  MSE: 1.49635, MAE: 0.88792
[Epoch 14] [Test] MSE: 1.51083, MAE: 0.89087

[Epoch 15/15] Training Loss: 0.85891	Elapsed Time: 2,331.05s (0:38:51)
[Epoch 15] [Dev]  MSE: 1.49822, MAE: 0.89712
[Epoch 15] [Test] MSE: 1.50973, MAE: 0.89926

[Training Loss]
[1.6998, 1.16959, 1.07351, 1.01402, 0.97615, 0.94801, 0.92689, 0.90904, 0.89744, 0.88869, 0.87912, 0.87235, 0.8671, 0.86392, 0.85891]

[Dev MSE]
[1.44119, 1.43131, 1.43869, 1.45599, 1.45667, 1.43111, 1.44219, 1.45272, 1.44853, 1.46962, 1.46855, 1.47771, 1.47047, 1.49635, 1.49822]
[Test MSE]
[1.44923, 1.44222, 1.4502, 1.46773, 1.46811, 1.44287, 1.4562, 1.4649, 1.46157, 1.48284, 1.4804, 1.4898, 1.48303, 1.51083, 1.50973]
[Test MAE]
[0.91915, 0.9439, 0.901, 0.89606, 0.92481, 0.91359, 0.9309, 0.90417, 0.9075, 0.89582, 0.89713, 0.89985, 0.90183, 0.89087, 0.89926]


Best Dev MSE: 1.43111 (Obtained during Evaluation #6)
Test MSE: 1.44287, Test MAE: 0.91359

End of Program! Elapsed Time: 2,351.29s (0:39:11)
