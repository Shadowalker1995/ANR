========================================================================================================================
  ARL_lr: 0.01
  ARL_path: Kindle_Store_ANRS_1337
  batch_size: 128
  command: -d Kindle_Store -m ANR -e 15 -p 1 -v 50000 -rs 5678 -gpu 0 -vb 1 -sm Kindle_Store_ANR -ARL_path Kindle_Store_ANRS_1337
  ctx_win_size: 3
  dataset: Kindle_Store
  disable_initial_eval: 0
  dropout_rate: 0.5
  epochs: 15
  gpu: 0
  h1: 10
  h2: 50
  input_dir: ./datasets/Kindle_Store/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  model: ANR
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Kindle_Store - ANR/
  pretrained_src: 1
  random_seed: 5678
  save_model: Kindle_Store_ANR
  use_cuda: True
  verbose: 1
  vocab_size: 50000
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 488,920, # of Items: 232,137

Creating model (Selected Model: ANR)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 4.11s (0.07 minute)

Loading uid_userDoc from "./datasets/Kindle_Store/Kindle_Store_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (488920, 500)]

Loading iid_itemDoc from "./datasets/Kindle_Store/Kindle_Store_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (232137, 500)]

Loading pretrained word embeddings from "./datasets/Kindle_Store/Kindle_Store_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (50002, 300)]

Loading pretrained ARL weights of "ANR" for dataset "Kindle_Store" from "./__saved_models__/Kindle_Store - ANRS/Kindle_Store_ANRS_1337.pth"!
Loading pretrained ARL weights on GPU "0"!

Loaded pretrained model states:

	shared_ANR_ARL.aspProj
	shared_ANR_ARL.aspEmbed.weight

Pretrained model states transferred to current model!

*** "shared_ANR_ARL.aspProj, shared_ANR_ARL.aspEmbed.weight" are FINE-TUNED!! ***


Initialization Complete.. Elapsed Time: 20.40s (0.34 minute)

Train/Dev/Test splits loaded! |TRAIN|: 800,000, |DEV|: 43,894, |TEST|: 43,882
Train/Dev/Test splits loaded! Elapsed Time: 20.65s (0.34 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 4.17751, MAE: 1.85237

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 4.22088, MAE: 1.86268

Initial Evaluation Complete.. Elapsed Time: 27.83s (0.46 minute)

Parameters that are fine-tuned using a smaller LR (LR: 2e-05):
shared_ANR_ARL.aspProj, shared_ANR_ARL.aspEmbed.weight

Parameters with L2 Regularization (Regularization Strength: 1e-06):
ANR_RatingPred.uid_userOffset.weight, ANR_RatingPred.iid_itemOffset.weight

Optimizer: Adam, Loss Function: MSELoss

Model Size: 376,266,508
# of Trainable Parameters: 737,408
ANR (
  (uid_userDoc): Embedding(488920, 500), weights = ((488920, 500),), parameters = 244,460,000
  (iid_itemDoc): Embedding(232137, 500), weights = ((232137, 500),), parameters = 116,068,500
  (wid_wEmbed): Embedding(50002, 300), weights = ((50002, 300),), parameters = 15,000,600
  (shared_ANR_ARL): ANR_ARL(
    (aspEmbed): Embedding(5, 30)
    (aspProj): Parameter(5, 300, 10)
  ), weights = ((5, 300, 10), (5, 30)), parameters = 15,150 (Trainable)
  (ANR_AIE): ANR_AIE(  (W_a): Parameter(10, 10)
    (W_u): Parameter(50, 10)
    (w_hu): Parameter(50, 1)
    (W_i): Parameter(50, 10)
    (w_hi): Parameter(50, 1)
  ), weights = ((10, 10), (50, 10), (50, 1), (50, 10), (50, 1)), parameters = 1,200 (Trainable)
  (ANR_RatingPred): ANR_RatingPred(
    (userAspRepDropout): Dropout(p=0.5, inplace=False)
    (itemAspRepDropout): Dropout(p=0.5, inplace=False)
    (uid_userOffset): Embedding(488920, 1)
    (iid_itemOffset): Embedding(232137, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (488920, 1), (232137, 1)), parameters = 721,058 (Trainable)
)
========================================================================================================================

[Epoch 1/15] Training Loss: 1.49992	Elapsed Time: 149.01s (0:02:29)
[Epoch 1] [Dev]  MSE: 0.82871, MAE: 0.67882
[Epoch 1] [Test] MSE: 0.83099, MAE: 0.68100

*** MODEL has obtained the best DEV MSE of 0.82871 so far!
*** MODEL saved to "./__saved_models__/Kindle_Store - ANR/Kindle_Store_ANR_5678.pth"

[Epoch 2/15] Training Loss: 0.82624	Elapsed Time: 305.16s (0:05:05)
[Epoch 2] [Dev]  MSE: 0.80755, MAE: 0.66497
[Epoch 2] [Test] MSE: 0.80838, MAE: 0.66704

*** MODEL has obtained the best DEV MSE of 0.80755 so far!
*** MODEL saved to "./__saved_models__/Kindle_Store - ANR/Kindle_Store_ANR_5678.pth"

[Epoch 3/15] Training Loss: 0.73406	Elapsed Time: 460.98s (0:07:40)
[Epoch 3] [Dev]  MSE: 0.82392, MAE: 0.65920
[Epoch 3] [Test] MSE: 0.82299, MAE: 0.66116

[Epoch 4/15] Training Loss: 0.67933	Elapsed Time: 616.91s (0:10:16)
[Epoch 4] [Dev]  MSE: 0.81083, MAE: 0.65849
[Epoch 4] [Test] MSE: 0.81171, MAE: 0.66038

[Epoch 5/15] Training Loss: 0.64420	Elapsed Time: 772.97s (0:12:52)
[Epoch 5] [Dev]  MSE: 0.81560, MAE: 0.64935
[Epoch 5] [Test] MSE: 0.81539, MAE: 0.65045

[Epoch 6/15] Training Loss: 0.62076	Elapsed Time: 928.90s (0:15:28)
[Epoch 6] [Dev]  MSE: 0.82731, MAE: 0.66659
[Epoch 6] [Test] MSE: 0.82547, MAE: 0.66716

[Epoch 7/15] Training Loss: 0.60446	Elapsed Time: 1,084.66s (0:18:04)
[Epoch 7] [Dev]  MSE: 0.82941, MAE: 0.64902
[Epoch 7] [Test] MSE: 0.82897, MAE: 0.65009

[Epoch 8/15] Training Loss: 0.59248	Elapsed Time: 1,240.69s (0:20:40)
[Epoch 8] [Dev]  MSE: 0.82317, MAE: 0.64979
[Epoch 8] [Test] MSE: 0.82286, MAE: 0.65077

[Epoch 9/15] Training Loss: 0.58299	Elapsed Time: 1,396.85s (0:23:16)
[Epoch 9] [Dev]  MSE: 0.82236, MAE: 0.65600
[Epoch 9] [Test] MSE: 0.82145, MAE: 0.65674

[Epoch 10/15] Training Loss: 0.57662	Elapsed Time: 1,552.75s (0:25:52)
[Epoch 10] [Dev]  MSE: 0.82776, MAE: 0.64885
[Epoch 10] [Test] MSE: 0.82584, MAE: 0.64905

[Epoch 11/15] Training Loss: 0.57081	Elapsed Time: 1,708.63s (0:28:28)
[Epoch 11] [Dev]  MSE: 0.82929, MAE: 0.65027
[Epoch 11] [Test] MSE: 0.82631, MAE: 0.65042

[Epoch 12/15] Training Loss: 0.56641	Elapsed Time: 1,864.57s (0:31:04)
[Epoch 12] [Dev]  MSE: 0.82457, MAE: 0.65463
[Epoch 12] [Test] MSE: 0.82218, MAE: 0.65523

[Epoch 13/15] Training Loss: 0.56297	Elapsed Time: 2,020.58s (0:33:40)
[Epoch 13] [Dev]  MSE: 0.84251, MAE: 0.64692
[Epoch 13] [Test] MSE: 0.84024, MAE: 0.64727

[Epoch 14/15] Training Loss: 0.55999	Elapsed Time: 2,176.39s (0:36:16)
[Epoch 14] [Dev]  MSE: 0.83755, MAE: 0.64502
[Epoch 14] [Test] MSE: 0.83881, MAE: 0.64640

[Epoch 15/15] Training Loss: 0.55772	Elapsed Time: 2,332.14s (0:38:52)
[Epoch 15] [Dev]  MSE: 0.83878, MAE: 0.66856
[Epoch 15] [Test] MSE: 0.83487, MAE: 0.66803

[Training Loss]
[1.49992, 0.82624, 0.73406, 0.67933, 0.6442, 0.62076, 0.60446, 0.59248, 0.58299, 0.57662, 0.57081, 0.56641, 0.56297, 0.55999, 0.55772]

[Dev MSE]
[0.82871, 0.80755, 0.82392, 0.81083, 0.8156, 0.82731, 0.82941, 0.82317, 0.82236, 0.82776, 0.82929, 0.82457, 0.84251, 0.83755, 0.83878]
[Test MSE]
[0.83099, 0.80838, 0.82299, 0.81171, 0.81539, 0.82547, 0.82897, 0.82286, 0.82145, 0.82584, 0.82631, 0.82218, 0.84024, 0.83881, 0.83487]
[Test MAE]
[0.681, 0.66704, 0.66116, 0.66038, 0.65045, 0.66716, 0.65009, 0.65077, 0.65674, 0.64905, 0.65042, 0.65523, 0.64727, 0.6464, 0.66803]


Best Dev MSE: 0.80755 (Obtained during Evaluation #2)
Test MSE: 0.80838, Test MAE: 0.66704

End of Program! Elapsed Time: 2,367.09s (0:39:27)
