========================================================================================================================
  ARL_lr: 0.01
  ARL_path: Kindle_Store_ANRS_1337
  batch_size: 128
  command: -d Kindle_Store -m ANR -e 15 -p 1 -v 50000 -rs 1234 -gpu 0 -vb 1 -sm Kindle_Store_ANR -ARL_path Kindle_Store_ANRS_1337
  ctx_win_size: 3
  dataset: Kindle_Store
  disable_initial_eval: 0
  dropout_rate: 0.5
  epochs: 15
  gpu: 0
  h1: 10
  h2: 50
  input_dir: ./datasets/Kindle_Store/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  model: ANR
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Kindle_Store - ANR/
  pretrained_src: 1
  random_seed: 1234
  save_model: Kindle_Store_ANR
  use_cuda: True
  verbose: 1
  vocab_size: 50000
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 488,920, # of Items: 232,137

Creating model (Selected Model: ANR)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 4.15s (0.07 minute)

Loading uid_userDoc from "./datasets/Kindle_Store/Kindle_Store_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (488920, 500)]

Loading iid_itemDoc from "./datasets/Kindle_Store/Kindle_Store_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (232137, 500)]

Loading pretrained word embeddings from "./datasets/Kindle_Store/Kindle_Store_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (50002, 300)]

Loading pretrained ARL weights of "ANR" for dataset "Kindle_Store" from "./__saved_models__/Kindle_Store - ANRS/Kindle_Store_ANRS_1337.pth"!
Loading pretrained ARL weights on GPU "0"!

Loaded pretrained model states:

	shared_ANR_ARL.aspProj
	shared_ANR_ARL.aspEmbed.weight

Pretrained model states transferred to current model!

*** "shared_ANR_ARL.aspProj, shared_ANR_ARL.aspEmbed.weight" are FINE-TUNED!! ***


Initialization Complete.. Elapsed Time: 24.48s (0.41 minute)

Train/Dev/Test splits loaded! |TRAIN|: 800,000, |DEV|: 43,894, |TEST|: 43,882
Train/Dev/Test splits loaded! Elapsed Time: 24.74s (0.41 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 4.17352, MAE: 1.85137

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 4.21689, MAE: 1.86167

Initial Evaluation Complete.. Elapsed Time: 31.98s (0.53 minute)

Parameters that are fine-tuned using a smaller LR (LR: 2e-05):
shared_ANR_ARL.aspProj, shared_ANR_ARL.aspEmbed.weight

Parameters with L2 Regularization (Regularization Strength: 1e-06):
ANR_RatingPred.uid_userOffset.weight, ANR_RatingPred.iid_itemOffset.weight

Optimizer: Adam, Loss Function: MSELoss

Model Size: 376,266,508
# of Trainable Parameters: 737,408
ANR (
  (uid_userDoc): Embedding(488920, 500), weights = ((488920, 500),), parameters = 244,460,000
  (iid_itemDoc): Embedding(232137, 500), weights = ((232137, 500),), parameters = 116,068,500
  (wid_wEmbed): Embedding(50002, 300), weights = ((50002, 300),), parameters = 15,000,600
  (shared_ANR_ARL): ANR_ARL(
    (aspEmbed): Embedding(5, 30)
    (aspProj): Parameter(5, 300, 10)
  ), weights = ((5, 300, 10), (5, 30)), parameters = 15,150 (Trainable)
  (ANR_AIE): ANR_AIE(  (W_a): Parameter(10, 10)
    (W_u): Parameter(50, 10)
    (w_hu): Parameter(50, 1)
    (W_i): Parameter(50, 10)
    (w_hi): Parameter(50, 1)
  ), weights = ((10, 10), (50, 10), (50, 1), (50, 10), (50, 1)), parameters = 1,200 (Trainable)
  (ANR_RatingPred): ANR_RatingPred(
    (userAspRepDropout): Dropout(p=0.5, inplace=False)
    (itemAspRepDropout): Dropout(p=0.5, inplace=False)
    (uid_userOffset): Embedding(488920, 1)
    (iid_itemOffset): Embedding(232137, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (488920, 1), (232137, 1)), parameters = 721,058 (Trainable)
)
========================================================================================================================

[Epoch 1/15] Training Loss: 1.50908	Elapsed Time: 149.28s (0:02:29)
[Epoch 1] [Dev]  MSE: 0.83403, MAE: 0.68001
[Epoch 1] [Test] MSE: 0.83449, MAE: 0.68110

*** MODEL has obtained the best DEV MSE of 0.83403 so far!
*** MODEL saved to "./__saved_models__/Kindle_Store - ANR/Kindle_Store_ANR_1234.pth"

[Epoch 2/15] Training Loss: 0.83092	Elapsed Time: 305.85s (0:05:05)
[Epoch 2] [Dev]  MSE: 0.81320, MAE: 0.67497
[Epoch 2] [Test] MSE: 0.81324, MAE: 0.67582

*** MODEL has obtained the best DEV MSE of 0.81320 so far!
*** MODEL saved to "./__saved_models__/Kindle_Store - ANR/Kindle_Store_ANR_1234.pth"

[Epoch 3/15] Training Loss: 0.74069	Elapsed Time: 462.28s (0:07:42)
[Epoch 3] [Dev]  MSE: 0.80695, MAE: 0.64350
[Epoch 3] [Test] MSE: 0.80718, MAE: 0.64378

*** MODEL has obtained the best DEV MSE of 0.80695 so far!
*** MODEL saved to "./__saved_models__/Kindle_Store - ANR/Kindle_Store_ANR_1234.pth"

[Epoch 4/15] Training Loss: 0.68356	Elapsed Time: 618.59s (0:10:18)
[Epoch 4] [Dev]  MSE: 0.80757, MAE: 0.65391
[Epoch 4] [Test] MSE: 0.80748, MAE: 0.65444

[Epoch 5/15] Training Loss: 0.64840	Elapsed Time: 774.86s (0:12:54)
[Epoch 5] [Dev]  MSE: 0.81399, MAE: 0.64720
[Epoch 5] [Test] MSE: 0.81546, MAE: 0.64903

[Epoch 6/15] Training Loss: 0.62274	Elapsed Time: 931.29s (0:15:31)
[Epoch 6] [Dev]  MSE: 0.83215, MAE: 0.64827
[Epoch 6] [Test] MSE: 0.82842, MAE: 0.64811

[Epoch 7/15] Training Loss: 0.60459	Elapsed Time: 1,087.73s (0:18:07)
[Epoch 7] [Dev]  MSE: 0.82690, MAE: 0.66840
[Epoch 7] [Test] MSE: 0.82148, MAE: 0.66876

[Epoch 8/15] Training Loss: 0.59265	Elapsed Time: 1,244.18s (0:20:44)
[Epoch 8] [Dev]  MSE: 0.82692, MAE: 0.64453
[Epoch 8] [Test] MSE: 0.82413, MAE: 0.64491

[Epoch 9/15] Training Loss: 0.58431	Elapsed Time: 1,400.58s (0:23:20)
[Epoch 9] [Dev]  MSE: 0.83228, MAE: 0.64424
[Epoch 9] [Test] MSE: 0.82955, MAE: 0.64461

[Epoch 10/15] Training Loss: 0.57570	Elapsed Time: 1,557.24s (0:25:57)
[Epoch 10] [Dev]  MSE: 0.82806, MAE: 0.64996
[Epoch 10] [Test] MSE: 0.82275, MAE: 0.64938

[Epoch 11/15] Training Loss: 0.57146	Elapsed Time: 1,713.56s (0:28:33)
[Epoch 11] [Dev]  MSE: 0.84232, MAE: 0.65088
[Epoch 11] [Test] MSE: 0.83951, MAE: 0.65167

[Epoch 12/15] Training Loss: 0.56744	Elapsed Time: 1,869.89s (0:31:09)
[Epoch 12] [Dev]  MSE: 0.83642, MAE: 0.65912
[Epoch 12] [Test] MSE: 0.83144, MAE: 0.65868

[Epoch 13/15] Training Loss: 0.56405	Elapsed Time: 2,026.14s (0:33:46)
[Epoch 13] [Dev]  MSE: 0.83177, MAE: 0.65254
[Epoch 13] [Test] MSE: 0.82706, MAE: 0.65276

[Epoch 14/15] Training Loss: 0.56050	Elapsed Time: 2,182.62s (0:36:22)
[Epoch 14] [Dev]  MSE: 0.84560, MAE: 0.65452
[Epoch 14] [Test] MSE: 0.84082, MAE: 0.65440

[Epoch 15/15] Training Loss: 0.55819	Elapsed Time: 2,338.87s (0:38:58)
[Epoch 15] [Dev]  MSE: 0.84180, MAE: 0.64978
[Epoch 15] [Test] MSE: 0.83735, MAE: 0.65003

[Training Loss]
[1.50908, 0.83092, 0.74069, 0.68356, 0.6484, 0.62274, 0.60459, 0.59265, 0.58431, 0.5757, 0.57146, 0.56744, 0.56405, 0.5605, 0.55819]

[Dev MSE]
[0.83403, 0.8132, 0.80695, 0.80757, 0.81399, 0.83215, 0.8269, 0.82692, 0.83228, 0.82806, 0.84232, 0.83642, 0.83177, 0.8456, 0.8418]
[Test MSE]
[0.83449, 0.81324, 0.80718, 0.80748, 0.81546, 0.82842, 0.82148, 0.82413, 0.82955, 0.82275, 0.83951, 0.83144, 0.82706, 0.84082, 0.83735]
[Test MAE]
[0.6811, 0.67582, 0.64378, 0.65444, 0.64903, 0.64811, 0.66876, 0.64491, 0.64461, 0.64938, 0.65167, 0.65868, 0.65276, 0.6544, 0.65003]


Best Dev MSE: 0.80695 (Obtained during Evaluation #3)
Test MSE: 0.80718, Test MAE: 0.64378

End of Program! Elapsed Time: 2,378.02s (0:39:38)
