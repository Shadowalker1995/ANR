========================================================================================================================
  ARL_lr: 0.01
  ARL_path: test_ANRS_1337
  batch_size: 128
  command: -d test -m ANR -e 15 -p 1 -v 19438 -rs 1337 -gpu 0 -vb 1 -ARL_path test_ANRS_1337
  ctx_win_size: 3
  dataset: test
  disable_initial_eval: 0
  dropout_rate: 0.5
  epochs: 15
  gpu: 0
  h1: 10
  h2: 50
  input_dir: ./datasets/test/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  model: ANR
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/test - ANR/
  pretrained_src: 1
  random_seed: 1337
  save_model: 
  use_cuda: True
  verbose: 1
  vocab_size: 19438
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 11,782, # of Items: 1,127

Creating model (Selected Model: ANR)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 1.22s (0.02 minute)

Loading uid_userDoc from "./datasets/test/test_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (11782, 500)]

Loading iid_itemDoc from "./datasets/test/test_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (1127, 500)]

Loading pretrained word embeddings from "./datasets/test/test_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (19440, 300)]

Loading pretrained ARL weights of "ANR" for dataset "test" from "./__saved_models__/test - ANRS/test_ANRS_1337.pth"!
Loading pretrained ARL weights on GPU "0"!

Loaded pretrained model states:

	shared_ANR_ARL.aspProj
	shared_ANR_ARL.aspEmbed.weight

Pretrained model states transferred to current model!

*** "shared_ANR_ARL.aspProj, shared_ANR_ARL.aspEmbed.weight" are FINE-TUNED!! ***


Initialization Complete.. Elapsed Time: 1.35s (0.02 minute)

Train/Dev/Test splits loaded! |TRAIN|: 15,873, |DEV|: 927, |TEST|: 940
Train/Dev/Test splits loaded! Elapsed Time: 1.36s (0.02 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 3.31729, MAE: 1.67110

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 3.51549, MAE: 1.73082

Initial Evaluation Complete.. Elapsed Time: 1.78s (0.03 minute)

Parameters that are fine-tuned using a smaller LR (LR: 2e-05):
shared_ANR_ARL.aspProj, shared_ANR_ARL.aspEmbed.weight

Parameters with L2 Regularization (Regularization Strength: 1e-06):
ANR_RatingPred.uid_userOffset.weight, ANR_RatingPred.iid_itemOffset.weight

Optimizer: Adam, Loss Function: MSELoss

Model Size: 12,315,760
# of Trainable Parameters: 29,260
ANR (
  (uid_userDoc): Embedding(11782, 500), weights = ((11782, 500),), parameters = 5,891,000
  (iid_itemDoc): Embedding(1127, 500), weights = ((1127, 500),), parameters = 563,500
  (wid_wEmbed): Embedding(19440, 300), weights = ((19440, 300),), parameters = 5,832,000
  (shared_ANR_ARL): ANR_ARL(
    (aspEmbed): Embedding(5, 30)
    (aspProj): Parameter(5, 300, 10)
  ), weights = ((5, 300, 10), (5, 30)), parameters = 15,150 (Trainable)
  (ANR_AIE): ANR_AIE(  (W_a): Parameter(10, 10)
    (W_u): Parameter(50, 10)
    (w_hu): Parameter(50, 1)
    (W_i): Parameter(50, 10)
    (w_hi): Parameter(50, 1)
  ), weights = ((10, 10), (50, 10), (50, 1), (50, 10), (50, 1)), parameters = 1,200 (Trainable)
  (ANR_RatingPred): ANR_RatingPred(
    (userAspRepDropout): Dropout(p=0.5, inplace=False)
    (itemAspRepDropout): Dropout(p=0.5, inplace=False)
    (uid_userOffset): Embedding(11782, 1)
    (iid_itemOffset): Embedding(1127, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (11782, 1), (1127, 1)), parameters = 12,910 (Trainable)
)
========================================================================================================================

[Epoch 1/15] Training Loss: 2.49545	Elapsed Time: 4.23s (0:00:04)
[Epoch 1] [Dev]  MSE: 1.34235, MAE: 0.96120
[Epoch 1] [Test] MSE: 1.53502, MAE: 1.03008

[Epoch 2/15] Training Loss: 2.16020	Elapsed Time: 8.72s (0:00:08)
[Epoch 2] [Dev]  MSE: 1.33067, MAE: 0.98877
[Epoch 2] [Test] MSE: 1.49654, MAE: 1.04997

[Epoch 3/15] Training Loss: 1.94566	Elapsed Time: 13.24s (0:00:13)
[Epoch 3] [Dev]  MSE: 1.17552, MAE: 0.88117
[Epoch 3] [Test] MSE: 1.33476, MAE: 0.93938

[Epoch 4/15] Training Loss: 1.90464	Elapsed Time: 17.78s (0:00:17)
[Epoch 4] [Dev]  MSE: 1.15776, MAE: 0.88992
[Epoch 4] [Test] MSE: 1.30279, MAE: 0.94385

[Epoch 5/15] Training Loss: 1.76621	Elapsed Time: 22.41s (0:00:22)
[Epoch 5] [Dev]  MSE: 1.10782, MAE: 0.84326
[Epoch 5] [Test] MSE: 1.24942, MAE: 0.89185

[Epoch 6/15] Training Loss: 1.65765	Elapsed Time: 27.04s (0:00:27)
[Epoch 6] [Dev]  MSE: 1.10796, MAE: 0.85898
[Epoch 6] [Test] MSE: 1.24500, MAE: 0.90854

[Epoch 7/15] Training Loss: 1.57971	Elapsed Time: 31.76s (0:00:31)
[Epoch 7] [Dev]  MSE: 1.13692, MAE: 0.88196
[Epoch 7] [Test] MSE: 1.27846, MAE: 0.93640

[Epoch 8/15] Training Loss: 1.45129	Elapsed Time: 36.30s (0:00:36)
[Epoch 8] [Dev]  MSE: 1.12586, MAE: 0.87227
[Epoch 8] [Test] MSE: 1.26935, MAE: 0.92839

[Epoch 9/15] Training Loss: 1.40605	Elapsed Time: 40.88s (0:00:40)
[Epoch 9] [Dev]  MSE: 1.11348, MAE: 0.85758
[Epoch 9] [Test] MSE: 1.25858, MAE: 0.91379

[Epoch 10/15] Training Loss: 1.30761	Elapsed Time: 45.50s (0:00:45)
[Epoch 10] [Dev]  MSE: 1.11268, MAE: 0.84446
[Epoch 10] [Test] MSE: 1.25156, MAE: 0.89745

[Epoch 11/15] Training Loss: 1.22167	Elapsed Time: 50.11s (0:00:50)
[Epoch 11] [Dev]  MSE: 1.18159, MAE: 0.90361
[Epoch 11] [Test] MSE: 1.32529, MAE: 0.96238

[Epoch 12/15] Training Loss: 1.15430	Elapsed Time: 54.75s (0:00:54)
[Epoch 12] [Dev]  MSE: 1.09663, MAE: 0.83153
[Epoch 12] [Test] MSE: 1.22900, MAE: 0.88319

[Epoch 13/15] Training Loss: 1.06888	Elapsed Time: 59.29s (0:00:59)
[Epoch 13] [Dev]  MSE: 1.10180, MAE: 0.85715
[Epoch 13] [Test] MSE: 1.22237, MAE: 0.90432

[Epoch 14/15] Training Loss: 0.98958	Elapsed Time: 63.93s (0:01:03)
[Epoch 14] [Dev]  MSE: 1.05345, MAE: 0.78655
[Epoch 14] [Test] MSE: 1.17332, MAE: 0.82893

[Epoch 15/15] Training Loss: 0.95927	Elapsed Time: 68.46s (0:01:08)
[Epoch 15] [Dev]  MSE: 1.05728, MAE: 0.76270
[Epoch 15] [Test] MSE: 1.17700, MAE: 0.80262

[Training Loss]
[2.49545, 2.1602, 1.94566, 1.90464, 1.76621, 1.65765, 1.57971, 1.45129, 1.40605, 1.30761, 1.22167, 1.1543, 1.06888, 0.98958, 0.95927]

[Dev MSE]
[1.34235, 1.33067, 1.17552, 1.15776, 1.10782, 1.10796, 1.13692, 1.12586, 1.11348, 1.11268, 1.18159, 1.09663, 1.1018, 1.05345, 1.05728]
[Test MSE]
[1.53502, 1.49654, 1.33476, 1.30279, 1.24942, 1.245, 1.27846, 1.26935, 1.25858, 1.25156, 1.32529, 1.229, 1.22237, 1.17332, 1.177]
[Test MAE]
[1.03008, 1.04997, 0.93938, 0.94385, 0.89185, 0.90854, 0.9364, 0.92839, 0.91379, 0.89745, 0.96238, 0.88319, 0.90432, 0.82893, 0.80262]


Best Dev MSE: 1.05345 (Obtained during Evaluation #14)
Test MSE: 1.17332, Test MAE: 0.82893

End of Program! Elapsed Time: 70.51s (0:01:10)
