========================================================================================================================
  ARL_lr: 0.01
  ARL_path: 
  batch_size: 128
  channels_global: 100
  channels_local: 200
  command: -d Books -m MSANR -e 10 -dr 0.9 -WED 300 -p 1 -v 50000 -K 5 -h1 50 -h2 50 -output_size 50 -rs 1234 -gpu 0 -vb 1 -sm Books_MSANR
  ctx_win_size: 3
  dataset: Books
  disable_initial_eval: 0
  dropout_rate: 0.9
  epochs: 10
  filters_num: 100
  gpu: 0
  h1: 50
  h2: 50
  hidden_size: 500
  input_dir: ./datasets/Books/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  max_vis_len: 500
  model: MSANR
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Books - MSANR/
  output_size: 50
  pretrained_src: 1
  random_seed: 1234
  save_model: Books_MSANR
  use_cuda: True
  verbose: 1
  vocab_size: 50000
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 621,433, # of Items: 390,310

Creating model (Selected Model: MSANR)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 5.42s (0.09 minute)

Loading uid_userDoc from "./datasets/Books/Books_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (621433, 500)]

Loading iid_itemDoc from "./datasets/Books/Books_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (390310, 500)]

Loading pretrained word embeddings from "./datasets/Books/Books_wed300_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (50002, 300)]

Initialization Complete.. Elapsed Time: 42.55s (0.71 minute)

Train/Dev/Test splits loaded! |TRAIN|: 800,000, |DEV|: 20,828, |TEST|: 21,246
Train/Dev/Test splits loaded! Elapsed Time: 42.82s (0.71 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 18.94018, MAE: 4.22143

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 19.09828, MAE: 4.24551

Initial Evaluation Complete.. Elapsed Time: 65.30s (1.09 minutes)

Parameters with L2 Regularization (Regularization Strength: 1e-06):
MSANR_RatingPred.uid_userOffset.weight, MSANR_RatingPred.iid_itemOffset.weight

Optimizer: Adam, Loss Function: MSELoss

Model Size: 521,965,094
# of Trainable Parameters: 1,092,994
MSANR (
  (uid_userDoc): Embedding(621433, 500), weights = ((621433, 500),), parameters = 310,716,500
  (iid_itemDoc): Embedding(390310, 500), weights = ((390310, 500),), parameters = 195,155,000
  (wid_wEmbed): Embedding(50002, 300), weights = ((50002, 300),), parameters = 15,000,600
  (MSANR_ARL): MSANR_ARL(
    (aspEmbed): ModuleList(
      (0): Embedding(5, 150)
      (1): Embedding(5, 250)
      (2): Embedding(5, 350)
      (3): Embedding(5, 450)
    )
    (filterEmbed): Embedding(5, 50)
    (aspProj): Parameter(5, 300, 50)
  ), weights = ((5, 300, 50), (5, 150), (5, 250), (5, 350), (5, 450), (5, 50)), parameters = 81,250 (Trainable)
  (MSANR_RatingPred): MSANR_RatingPred(
    (userAspRepDropout): Dropout(p=0.9, inplace=False)
    (itemAspRepDropout): Dropout(p=0.9, inplace=False)
    (uid_userOffset): Embedding(621433, 1)
    (iid_itemOffset): Embedding(390310, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (621433, 1), (390310, 1)), parameters = 1,011,744 (Trainable)
)
========================================================================================================================

[Epoch 1/10] Training Loss: 2.18600	Elapsed Time: 1,058.87s (0:17:38)
[Epoch 1] [Dev]  MSE: 1.02353, MAE: 0.77024
[Epoch 1] [Test] MSE: 0.98161, MAE: 0.75892

*** MODEL has obtained the best DEV MSE of 1.02353 so far!
*** The Best MODEL saved to "./__saved_models__/Books - MSANR/Books_MSANR_1234.pth"

[Epoch 2/10] Training Loss: 1.29038	Elapsed Time: 2,139.75s (0:35:39)
[Epoch 2] [Dev]  MSE: 1.00761, MAE: 0.74935
[Epoch 2] [Test] MSE: 0.96697, MAE: 0.73925

*** MODEL has obtained the best DEV MSE of 1.00761 so far!
*** The Best MODEL saved to "./__saved_models__/Books - MSANR/Books_MSANR_1234.pth"

[Epoch 3/10] Training Loss: 0.97095	Elapsed Time: 3,224.97s (0:53:44)
[Epoch 3] [Dev]  MSE: 0.98983, MAE: 0.74043
[Epoch 3] [Test] MSE: 0.95309, MAE: 0.73077

*** MODEL has obtained the best DEV MSE of 0.98983 so far!
*** The Best MODEL saved to "./__saved_models__/Books - MSANR/Books_MSANR_1234.pth"

[Epoch 4/10] Training Loss: 0.89039	Elapsed Time: 4,311.50s (1:11:51)
[Epoch 4] [Dev]  MSE: 0.99655, MAE: 0.72897
[Epoch 4] [Test] MSE: 0.95927, MAE: 0.71702

[Epoch 5/10] Training Loss: 0.84181	Elapsed Time: 5,398.33s (1:29:58)
[Epoch 5] [Dev]  MSE: 0.99380, MAE: 0.72984
[Epoch 5] [Test] MSE: 0.95853, MAE: 0.71898

[Epoch 6/10] Training Loss: 0.80410	Elapsed Time: 6,485.26s (1:48:05)
[Epoch 6] [Dev]  MSE: 0.99061, MAE: 0.73407
[Epoch 6] [Test] MSE: 0.95883, MAE: 0.72425

[Epoch 7/10] Training Loss: 0.82099	Elapsed Time: 7,572.36s (2:06:12)
[Epoch 7] [Dev]  MSE: 0.99835, MAE: 0.73157
[Epoch 7] [Test] MSE: 0.96496, MAE: 0.72142

[Epoch 8/10] Training Loss: 0.79428	Elapsed Time: 8,659.37s (2:24:19)
[Epoch 8] [Dev]  MSE: 1.00193, MAE: 0.73369
[Epoch 8] [Test] MSE: 0.96917, MAE: 0.72402

[Epoch 9/10] Training Loss: 0.75354	Elapsed Time: 9,746.38s (2:42:26)
[Epoch 9] [Dev]  MSE: 1.00023, MAE: 0.73522
[Epoch 9] [Test] MSE: 0.96754, MAE: 0.72576

[Epoch 10/10] Training Loss: 0.77671	Elapsed Time: 10,833.43s (3:00:33)
[Epoch 10] [Dev]  MSE: 1.00058, MAE: 0.73510
[Epoch 10] [Test] MSE: 0.97001, MAE: 0.72576
*** The Last MODEL saved to "./__saved_models__/Books - MSANR/Books_MSANR_1234_10.pth"

[Training Loss]
[2.186, 1.29038, 0.97095, 0.89039, 0.84181, 0.8041, 0.82099, 0.79428, 0.75354, 0.77671]

[Dev MSE]
[1.02353, 1.00761, 0.98983, 0.99655, 0.9938, 0.99061, 0.99835, 1.00193, 1.00023, 1.00058]
[Test MSE]
[0.98161, 0.96697, 0.95309, 0.95927, 0.95853, 0.95883, 0.96496, 0.96917, 0.96754, 0.97001]
[Test MAE]
[0.75892, 0.73925, 0.73077, 0.71702, 0.71898, 0.72425, 0.72142, 0.72402, 0.72576, 0.72576]


Best Dev MSE: 0.98983 (Obtained during Evaluation #3)
Test MSE: 0.95309, Test MAE: 0.73077

End of Program! Elapsed Time: 10,920.46s (3:02:00)
