[args from argparse.ArgumentParser().parse_args()]
command: preprocessing_simple.py -d Kindle_Store -dev_test_in_train 1
dataset: Kindle_Store
dataset_maximum_size: 1000000
dev_test_in_train: True
maxDL: 500
maxVL: 500
minImages: 1
minReviews: 1
minRL: 10
random_seed: 1337
train_ratio: 0.8
vocab: 50000

[INPUT] Source Folder:       ../datasets/
[INPUT] Reviews/Ratings:     ../datasets/reviews_Kindle_Store.json

[OUTPUT] Category Folder:    ../datasets/Kindle_Store/
[OUTPUT] env:                ../datasets/Kindle_Store/Kindle_Store_env.pkl
[OUTPUT] info:               ../datasets/Kindle_Store/Kindle_Store_info.pkl
[OUTPUT] interactions:       ../datasets/Kindle_Store/Kindle_Store_interactions.pkl
[OUTPUT] train_interactions: ../datasets/Kindle_Store/Kindle_Store_train_interactions.pkl
[OUTPUT] dev_interactions:   ../datasets/Kindle_Store/Kindle_Store_dev_interactions.pkl
[OUTPUT] test_interactions:  ../datasets/Kindle_Store/Kindle_Store_test_interactions.pkl
[OUTPUT] split_train:        ../datasets/Kindle_Store/Kindle_Store_split_train.pkl
[OUTPUT] split_dev:          ../datasets/Kindle_Store/Kindle_Store_split_dev.pkl
[OUTPUT] split_test:         ../datasets/Kindle_Store/Kindle_Store_split_test.pkl
[OUTPUT] uid_userDoc:        ../datasets/Kindle_Store/Kindle_Store_uid_userDoc.npy
[OUTPUT] iid_itemDoc:        ../datasets/Kindle_Store/Kindle_Store_iid_itemDoc.npy
[OUTPUT] uid_userDoc:        ../datasets/Kindle_Store/Kindle_Store_uid_userVis.npy
[OUTPUT] iid_itemDoc:        ../datasets/Kindle_Store/Kindle_Store_iid_itemVis.npy

[Settings]
Min reviews for user/item: 1
Min review length to qualify as an user-item interaction: 10
Max words for user/item document: 500 (For truncating/padding to get a fixed-size representation)
Top-50000 words in vocabulary being utilized!


Initial pass of reviews to get the user-item interactions!
[Initial stats] Users: 1,406,890, Items: 430,530, Ratings: 3,205,467, Density: 0.0000053


Second pass of visual features to get the item-feature interactions!
[Second stats] Items with image: 430,456, Images: 430,456, Density: 1.0000000

[Current stats] Users: 1385190, Items: 426322, Ratings: 3164666, Density: 0.0000054
[Current stats] Users: 1385190, Items: 426322, Ratings: 3164666, Density: 0.0000054

No change in # of users or # of items!

[Final stats] Users: 1,385,190, Items: 426,322, Ratings: 3,164,666, Density: 0.0000054

No change in # of users or # of items!

[Final stats] Users: 1,385,190, Items: 426,322, Ratings: 3,164,666, Density: 0.0000054


Third pass of reviews to get the rating, date, the num of tokenized review and index!
[Current stats] Users: 1,385,190, Items: 426,322, Ratings: 3,164,666, Density: 0.0000054

Filtering user-item interactions based on minimum review length of 10 tokens..
[Current stats] Users: 1,373,928, Items: 425,389, Ratings: 3,144,134, Density: 0.0000054


No change in # of users or # of items!

[Final stats] Users: 1,373,928, Items: 425,389, Ratings: 3,144,134, Density: 0.0000054

*****************************************************************************************************************************
*** Original Dataset Size (i.e. num_ratings): 3,144,134!
*** Selecting a random subsample of 1,000,000 user-item interactions!
*** Current Dataset Size (i.e. num_ratings):  1,000,000!
*****************************************************************************************************************************
[Current stats] Users: 583,374, Items: 259,979, Ratings: 1,000,000, Density: 0.0000066
