[args from argparse.ArgumentParser().parse_args()]
command: preprocessing_simple.py -d Grocery_and_Gourmet_Food -dev_test_in_train 1
dataset: Grocery_and_Gourmet_Food
dataset_maximum_size: 1000000
dev_test_in_train: True
maxDL: 500
maxVL: 500
minImages: 1
minReviews: 1
minRL: 10
random_seed: 1337
train_ratio: 0.8
vocab: 50000

[INPUT] Source Folder:       ../datasets/
[INPUT] Reviews/Ratings:     ../datasets/reviews_Grocery_and_Gourmet_Food.json

[OUTPUT] Category Folder:    ../datasets/Grocery_and_Gourmet_Food/
[OUTPUT] env:                ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_env.pkl
[OUTPUT] info:               ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_info.pkl
[OUTPUT] interactions:       ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_interactions.pkl
[OUTPUT] train_interactions: ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_train_interactions.pkl
[OUTPUT] dev_interactions:   ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_dev_interactions.pkl
[OUTPUT] test_interactions:  ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_test_interactions.pkl
[OUTPUT] split_train:        ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_split_train.pkl
[OUTPUT] split_dev:          ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_split_dev.pkl
[OUTPUT] split_test:         ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_split_test.pkl
[OUTPUT] uid_userDoc:        ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_uid_userDoc.npy
[OUTPUT] iid_itemDoc:        ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_iid_itemDoc.npy
[OUTPUT] uid_userDoc:        ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_uid_userVis.npy
[OUTPUT] iid_itemDoc:        ../datasets/Grocery_and_Gourmet_Food/Grocery_and_Gourmet_Food_iid_itemVis.npy

[Settings]
Min reviews for user/item: 1
Min review length to qualify as an user-item interaction: 10
Max words for user/item document: 500 (For truncating/padding to get a fixed-size representation)
Top-50000 words in vocabulary being utilized!


Initial pass of reviews to get the user-item interactions!
[Initial stats] Users: 768,438, Items: 166,049, Ratings: 1,297,156, Density: 0.0000102


Second pass of visual features to get the item-feature interactions!
[Second stats] Items with image: 170,361, Images: 170,361, Density: 1.0000000

[Current stats] Users: 763108, Items: 164691, Ratings: 1284178, Density: 0.0000102
[Current stats] Users: 763108, Items: 164691, Ratings: 1284178, Density: 0.0000102

No change in # of users or # of items!

[Final stats] Users: 763,108, Items: 164,691, Ratings: 1,284,178, Density: 0.0000102

No change in # of users or # of items!

[Final stats] Users: 763,108, Items: 164,691, Ratings: 1,284,178, Density: 0.0000102


Third pass of reviews to get the rating, date, the num of tokenized review and index!
[Current stats] Users: 763,108, Items: 164,691, Ratings: 1,284,178, Density: 0.0000102

Filtering user-item interactions based on minimum review length of 10 tokens..
[Current stats] Users: 755,624, Items: 163,811, Ratings: 1,271,319, Density: 0.0000103


No change in # of users or # of items!

[Final stats] Users: 755,624, Items: 163,811, Ratings: 1,271,319, Density: 0.0000103

*****************************************************************************************************************************
*** Original Dataset Size (i.e. num_ratings): 1,271,319!
*** Selecting a random subsample of 1,000,000 user-item interactions!
*** Current Dataset Size (i.e. num_ratings):  1,000,000!
*****************************************************************************************************************************
[Current stats] Users: 629,302, Items: 148,114, Ratings: 1,000,000, Density: 0.0000107
