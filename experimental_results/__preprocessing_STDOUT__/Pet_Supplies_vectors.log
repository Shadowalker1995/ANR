
Dataset: Pet_Supplies

[args from argparse.ArgumentParser().parse_args()]
command: pretrained_vectors_simple.py -d Pet_Supplies
dataset: Pet_Supplies
emb_dim: 300
emb_rand_init: 0.01
random_seed: 1337

[INPUT] Source Folder:                 ../datasets/
[INPUT] Category Folder:               ../datasets/Pet_Supplies/
[INPUT] env:                           ../datasets/Pet_Supplies/Pet_Supplies_env.pkl
[INPUT] Pretrained Word Embeddings:    ../datasets/GoogleNews-vectors-negative300.bin

[OUTPUT] wid_wordEmbed:                ../datasets/Pet_Supplies/Pet_Supplies_wid_wordEmbed.npy

Loading word-to-wid mappings (i.e. word_wid) from "../datasets/Pet_Supplies/Pet_Supplies_env.pkl"

|V|: 50002

Finished processing pretrained embeddings..
# of words with pretrained embeddings: 38361

Embedding Matrix=(50002, 300), |V|=50002
# of Words w/ No Pretrained Embeddings=11641 (23.281%)

Embeddings successfully saved to '../datasets/Pet_Supplies/Pet_Supplies_wid_wordEmbed.npy'


Pretrained word embeddings for "Pet_Supplies" obtained after 16.89 seconds (0.28 minutes)

