
Dataset: Books

[args from argparse.ArgumentParser().parse_args()]
command: pretrained_vectors_simple.py -d Books
dataset: Books
emb_dim: 300
emb_rand_init: 0.01
random_seed: 1337

[INPUT] Source Folder:                 ../datasets/
[INPUT] Category Folder:               ../datasets/Books/
[INPUT] env:                           ../datasets/Books/Books_env.pkl
[INPUT] Pretrained Word Embeddings:    ../datasets/GoogleNews-vectors-negative300.bin

[OUTPUT] wid_wordEmbed:                ../datasets/Books/Books_wid_wordEmbed.npy

Loading word-to-wid mappings (i.e. word_wid) from "../datasets/Books/Books_env.pkl"

|V|: 50002

Finished processing pretrained embeddings..
# of words with pretrained embeddings: 40705

Embedding Matrix=(50002, 300), |V|=50002
# of Words w/ No Pretrained Embeddings=9297 (18.593%)

Embeddings successfully saved to '../datasets/Books/Books_wid_wordEmbed.npy'


Pretrained word embeddings for "Books" obtained after 17.12 seconds (0.29 minutes)

