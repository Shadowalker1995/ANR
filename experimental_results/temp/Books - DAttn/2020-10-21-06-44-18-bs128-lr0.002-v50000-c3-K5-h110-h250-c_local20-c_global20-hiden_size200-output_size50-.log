========================================================================================================================
  ARL_lr: 0.01
  ARL_path: 
  batch_size: 128
  channels_global: 20
  channels_local: 20
  command: -d Books -m DAttn -e 10 -p 1 -v 50000 -K 5 -h1 10 -h2 50 -WED 300 -c_local 20 -c_global 20 -hiden_size 200 -output_size 50 -rs 1234 -gpu 0 -vb 1 -sm Books_DAttn
  ctx_win_size: 3
  dataset: Books
  disable_initial_eval: 0
  dropout_rate: 0.5
  epochs: 10
  gpu: 0
  h1: 10
  h2: 50
  hidden_size: 200
  input_dir: ./datasets/Books/
  L2_reg: 1e-06
  learning_rate: 0.002
  loss_function: MSELoss
  max_doc_len: 500
  max_vis_len: 500
  model: DAttn
  num_aspects: 5
  optimizer: Adam
  out_dir: ./experimental_results/Books - DAttn/
  output_size: 50
  pretrained_src: 1
  random_seed: 1234
  save_model: Books_DAttn
  use_cuda: True
  verbose: 1
  vocab_size: 50000
  word_embed_dim: 300
========================================================================================================================

[INFO] # of Users: 621,433, # of Items: 390,310

Creating model (Selected Model: DAttn)..
[args.use_cuda: True] Model is on the GPU! (args.gpu: 0, torch.cuda.current_device(): 0)
Model created! Elapsed Time: 5.36s (0.09 minute)

Loading uid_userDoc from "./datasets/Books/Books_uid_userDoc.npy"..
uid_userDoc loaded! [uid_userDoc: (621433, 500)]

Loading iid_itemDoc from "./datasets/Books/Books_iid_itemDoc.npy"..
iid_itemDoc loaded! [iid_itemDoc: (390310, 500)]

Loading pretrained word embeddings from "./datasets/Books/Books_wid_wordEmbed.npy"..
Pretrained word embeddings loaded! [wid_wEmbed: (50002, 300)]

Initialization Complete.. Elapsed Time: 42.70s (0.71 minute)

Train/Dev/Test splits loaded! |TRAIN|: 800,000, |DEV|: 20,828, |TEST|: 21,246
Train/Dev/Test splits loaded! Elapsed Time: 43.03s (0.72 minute)

Performing initial evaluation for VALIDATION set..
[Initial] [Dev]  MSE: 17.89683, MAE: 4.09591

Performing initial evaluation for TESTING set..
[Initial] [Test] MSE: 18.04909, MAE: 4.11999

Initial Evaluation Complete.. Elapsed Time: 64.74s (1.08 minutes)

Optimizer: Adam, Loss Function: MSELoss

Model Size: 522,332,058
# of Trainable Parameters: 1,459,958
DAttn (
  (uid_userDoc): Embedding(621433, 500), weights = ((621433, 500),), parameters = 310,716,500
  (iid_itemDoc): Embedding(390310, 500), weights = ((390310, 500),), parameters = 195,155,000
  (wid_wEmbed): Embedding(50002, 300), weights = ((50002, 300),), parameters = 15,000,600
  (DAttn_RatingPred): DAttn_RatingPred(
    (uid_userOffset): Embedding(621433, 1)
    (iid_itemOffset): Embedding(390310, 1)
    (globalOffset): Parameter(1,)
  ), weights = ((1,), (621433, 1), (390310, 1)), parameters = 1,011,744 (Trainable)
  (localAttentionLayer_user): LocalAttention(
    (attention_layer): Sequential(
      (0): Conv2d(1, 1, kernel_size=(3, 300), stride=(1, 1))
      (1): Sigmoid()
    )
    (cnn): Sequential(
      (0): Conv2d(1, 20, kernel_size=(1, 300), stride=(1, 1))
      (1): Tanh()
      (2): MaxPool2d(kernel_size=(500, 1), stride=(500, 1), padding=0, dilation=1, ceil_mode=False)
    )
  ), weights = ((1, 1, 3, 300), (1,), (20, 1, 1, 300), (20,)), parameters = 6,921 (Trainable)
  (globalAttentionLayer_user): GlobalAttention(
    (attention_layer): Sequential(
      (0): Conv2d(1, 1, kernel_size=(500, 300), stride=(1, 1))
      (1): Sigmoid()
    )
    (cnn_1): Sequential(
      (0): Conv2d(1, 20, kernel_size=(2, 300), stride=(1, 1))
      (1): Tanh()
      (2): MaxPool2d(kernel_size=(499, 1), stride=(499, 1), padding=0, dilation=1, ceil_mode=False)
    )
    (cnn_2): Sequential(
      (0): Conv2d(1, 20, kernel_size=(3, 300), stride=(1, 1))
      (1): Tanh()
      (2): MaxPool2d(kernel_size=(498, 1), stride=(498, 1), padding=0, dilation=1, ceil_mode=False)
    )
    (cnn_3): Sequential(
      (0): Conv2d(1, 20, kernel_size=(4, 300), stride=(1, 1))
      (1): Tanh()
      (2): MaxPool2d(kernel_size=(497, 1), stride=(497, 1), padding=0, dilation=1, ceil_mode=False)
    )
  ), weights = ((1, 1, 500, 300), (1,), (20, 1, 2, 300), (20,), (20, 1, 3, 300), (20,), (20, 1, 4, 300), (20,)), parameters = 204,061 (Trainable)
  (localAttentionLayer_item): LocalAttention(
    (attention_layer): Sequential(
      (0): Conv2d(1, 1, kernel_size=(3, 300), stride=(1, 1))
      (1): Sigmoid()
    )
    (cnn): Sequential(
      (0): Conv2d(1, 20, kernel_size=(1, 300), stride=(1, 1))
      (1): Tanh()
      (2): MaxPool2d(kernel_size=(500, 1), stride=(500, 1), padding=0, dilation=1, ceil_mode=False)
    )
  ), weights = ((1, 1, 3, 300), (1,), (20, 1, 1, 300), (20,)), parameters = 6,921 (Trainable)
  (globalAttentionLayer_item): GlobalAttention(
    (attention_layer): Sequential(
      (0): Conv2d(1, 1, kernel_size=(500, 300), stride=(1, 1))
      (1): Sigmoid()
    )
    (cnn_1): Sequential(
      (0): Conv2d(1, 20, kernel_size=(2, 300), stride=(1, 1))
      (1): Tanh()
      (2): MaxPool2d(kernel_size=(499, 1), stride=(499, 1), padding=0, dilation=1, ceil_mode=False)
    )
    (cnn_2): Sequential(
      (0): Conv2d(1, 20, kernel_size=(3, 300), stride=(1, 1))
      (1): Tanh()
      (2): MaxPool2d(kernel_size=(498, 1), stride=(498, 1), padding=0, dilation=1, ceil_mode=False)
    )
    (cnn_3): Sequential(
      (0): Conv2d(1, 20, kernel_size=(4, 300), stride=(1, 1))
      (1): Tanh()
      (2): MaxPool2d(kernel_size=(497, 1), stride=(497, 1), padding=0, dilation=1, ceil_mode=False)
    )
  ), weights = ((1, 1, 500, 300), (1,), (20, 1, 2, 300), (20,), (20, 1, 3, 300), (20,), (20, 1, 4, 300), (20,)), parameters = 204,061 (Trainable)
  (fcLayer): Sequential (
    (0): Linear(in_features=80, out_features=200, bias=True), weights = ((200, 80), (200,)), parameters = 16,200 (Trainable)
    (1): Dropout(p=0.5, inplace=False), weights = (), parameters = 0
    (2): ReLU(), weights = (), parameters = 0
    (3): Linear(in_features=200, out_features=50, bias=True), weights = ((50, 200), (50,)), parameters = 10,050 (Trainable)
  ), weights = ((200, 80), (200,), (50, 200), (50,)), parameters = 26,250 (Trainable)
)
========================================================================================================================

[Epoch 1/10] Training Loss: 0.74527	Elapsed Time: 1,183.94s (0:19:43)
[Epoch 1] [Dev]  MSE: 1.13140, MAE: 0.81508
[Epoch 1] [Test] MSE: 1.09462, MAE: 0.80307

*** MODEL has obtained the best DEV MSE of 1.13140 so far!
*** The Best MODEL saved to "./__saved_models__/Books - DAttn/Books_DAttn_1234.pth"

[Epoch 2/10] Training Loss: 0.54977	Elapsed Time: 2,389.42s (0:39:49)
[Epoch 2] [Dev]  MSE: 1.11176, MAE: 0.77364
[Epoch 2] [Test] MSE: 1.07919, MAE: 0.76129

*** MODEL has obtained the best DEV MSE of 1.11176 so far!
*** The Best MODEL saved to "./__saved_models__/Books - DAttn/Books_DAttn_1234.pth"

[Epoch 3/10] Training Loss: 0.45908	Elapsed Time: 3,594.90s (0:59:54)
[Epoch 3] [Dev]  MSE: 1.17578, MAE: 0.77154
[Epoch 3] [Test] MSE: 1.14415, MAE: 0.76132

[Epoch 4/10] Training Loss: 0.39496	Elapsed Time: 4,800.49s (1:20:00)
[Epoch 4] [Dev]  MSE: 1.14745, MAE: 0.78033
[Epoch 4] [Test] MSE: 1.12399, MAE: 0.77088

[Epoch 5/10] Training Loss: 0.34461	Elapsed Time: 6,006.19s (1:40:06)
[Epoch 5] [Dev]  MSE: 1.20274, MAE: 0.77849
[Epoch 5] [Test] MSE: 1.16928, MAE: 0.76647

[Epoch 6/10] Training Loss: 0.30427	Elapsed Time: 7,211.75s (2:00:11)
[Epoch 6] [Dev]  MSE: 1.16417, MAE: 0.77036
[Epoch 6] [Test] MSE: 1.13386, MAE: 0.75994

[Epoch 7/10] Training Loss: 0.27219	Elapsed Time: 8,417.27s (2:20:17)
[Epoch 7] [Dev]  MSE: 1.17846, MAE: 0.77172
[Epoch 7] [Test] MSE: 1.15042, MAE: 0.76230

[Epoch 8/10] Training Loss: 0.24452	Elapsed Time: 9,622.88s (2:40:22)
[Epoch 8] [Dev]  MSE: 1.20637, MAE: 0.78170
[Epoch 8] [Test] MSE: 1.17537, MAE: 0.77163

[Epoch 9/10] Training Loss: 0.22296	Elapsed Time: 10,828.56s (3:00:28)
[Epoch 9] [Dev]  MSE: 1.19244, MAE: 0.77700
[Epoch 9] [Test] MSE: 1.16203, MAE: 0.76822

[Epoch 10/10] Training Loss: 0.20368	Elapsed Time: 12,034.10s (3:20:34)
[Epoch 10] [Dev]  MSE: 1.24219, MAE: 0.79857
[Epoch 10] [Test] MSE: 1.21283, MAE: 0.78903
*** The Last MODEL saved to "./__saved_models__/Books - DAttn/Books_DAttn_1234_10.pth"

[Training Loss]
[0.74527, 0.54977, 0.45908, 0.39496, 0.34461, 0.30427, 0.27219, 0.24452, 0.22296, 0.20368]

[Dev MSE]
[1.1314, 1.11176, 1.17578, 1.14745, 1.20274, 1.16417, 1.17846, 1.20637, 1.19244, 1.24219]
[Test MSE]
[1.09462, 1.07919, 1.14415, 1.12399, 1.16928, 1.13386, 1.15042, 1.17537, 1.16203, 1.21283]
[Test MAE]
[0.80307, 0.76129, 0.76132, 0.77088, 0.76647, 0.75994, 0.7623, 0.77163, 0.76822, 0.78903]


Best Dev MSE: 1.11176 (Obtained during Evaluation #2)
Test MSE: 1.07919, Test MAE: 0.76129

End of Program! Elapsed Time: 12,120.53s (3:22:00)
